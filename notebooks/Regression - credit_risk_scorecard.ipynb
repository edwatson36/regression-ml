{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Credit risk scorecards using linear and logistic regression models\n",
        "**Sections summary**\n",
        "1. Create and clean 2 data subsets based on 'Duration'\n",
        "2. Create train and validation sets for each subset\n",
        "3. Select 4 features including 1 continuous and 1 non-binary categorical\n",
        "4. Build scorecards using linear and logistic regression\n",
        "5. Evaluation metrics"
      ],
      "metadata": {
        "id": "ZdjcIEE-2Cec"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dgPTAhoWmn-s"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "\n",
        "# Core\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import seaborn as sns\n",
        "\n",
        "# Model\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA IMPORT**"
      ],
      "metadata": {
        "id": "sDLn2J3B2fhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "\n",
        "url = \"https://github.com/edwatson36/regression-ml/blob/main/data/raw/GermanCreditData.csv\"\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "SjbIKFvJnBfA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "1eb1ead1-3316-46c5-ed0d-06a94371a942"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "HTTP Error 404: Not Found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1645168175.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://github.com/edwatson36/regression-ml/blob/main/data/raw/GermanCreditData.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# assuming storage_options is to be interpreted as headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mreq_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    631\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check import has worked (shape should = 1000, 22)\n",
        "\n",
        "print(df.shape)\n",
        "df.head(1)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OgewhRRbnJab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1\n",
        "\n",
        "Step 1: Check and clean data - converted 'X' values in 'qPurpose' column to 10 ('other' category). No other issues found.\n",
        "\n",
        "Step 2: Split data based on nDuration.\n",
        "\n"
      ],
      "metadata": {
        "id": "ygK2axlU2cdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Check and clean data\n",
        "\n",
        "# Check column types # all int64 except qPurpose=object\n",
        "print(\"\\nColumn Names and Data Types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# Find unique values in qPurpose\n",
        "print(f\"\\nUnique values in qPurpose: {df['qPurpose'].unique()}\")\n",
        "print(f\"Number of 'X' in qPurpose: {df['qPurpose'].eq('X').sum()}\")\n",
        "\n",
        "# Convert 'X' to 10 (='other')\n",
        "df['qPurpose'] = df['qPurpose'].replace('X', 10).astype(int)\n",
        "print(f\"\\nUnique values in qPurpose after conversion: {df['qPurpose'].unique()}\") # check conversion\n",
        "print(f\"qPurpose column type: {df['qPurpose'].dtype}\") # check column type\n",
        "\n",
        "# Check for blanks # no nulls\n",
        "print(\"\\nColumns and the number of NaNs\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Check for duplicates\n",
        "print(f\"\\nDuplicate rows: {df.duplicated().sum()}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VfW_XgGu3kmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram of all columns - visual check for issues/imbalances\n",
        "df.hist(bins=50, figsize=(20,15))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "US69aRP08M39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Split data\n",
        "\n",
        "# Create lists of categorical and numerical variables for ease of future reference\n",
        "categorical_cols = [col for col in df.columns if col.startswith('q')]\n",
        "numerical_cols = [col for col in df.columns if col.startswith('n')]\n",
        "\n",
        "print(f\"Categorical columns: {categorical_cols}\")\n",
        "print(f\"Numerical columns: {numerical_cols}\")"
      ],
      "metadata": {
        "id": "f4TI3HlC2_ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 2 subsets based on 'nDuration'\n",
        "df1 = df[df['nDuration'] <= 12].copy()\n",
        "df2 = df[df['nDuration'] > 12].copy()\n",
        "\n",
        "# List of DataFrames to iterate through\n",
        "dfs = [df1, df2]\n",
        "\n",
        "print(f\"df1 shape: {df1.shape}\")\n",
        "print(f\"df2 shape: {df2.shape}\")"
      ],
      "metadata": {
        "id": "sTUoUNg-JNdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2\n",
        "\n",
        "Step 1: Visual inspection of each subset using histograms to identify class imblances. Identifies the need to stratify based on target variable (more Goods than Bads). No intuition about particularly important predictive variables therefore no other stratification applied.\n",
        "\n",
        "Step 2: Drop 'Bad' column, keep 'Good' column as target variable (y). This means that our models we be predicting 'Good' as 1, the positive class.\n",
        "\n",
        "Step 3: Create train-validation splits. 20% chosen to maximise the amount of train data available whilst keeping a representative portion of data back for validation. Note that we have small amounts of data, particularly after creating the subsets based on duration."
      ],
      "metadata": {
        "id": "NGApn8tJ2_0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram of all columns - visual check for issues/imbalances\n",
        "df1.hist(bins=50, figsize=(20,15))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yh3ncWhq_CsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram of all columns - visual check for issues/imbalances\n",
        "df2.hist(bins=50, figsize=(20,15))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hBbKh6wf_EET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select target variable column, drop redundant column\n",
        "\n",
        "# Drop 'Bad' column\n",
        "for d in dfs:\n",
        "    d.drop(['Bad'], axis=1, inplace=True)\n",
        "\n",
        "# Check\n",
        "print(f\"df1 shape: {df1.shape}\")\n",
        "print(f\"df2 shape: {df2.shape}\")"
      ],
      "metadata": {
        "id": "KBXCP1ejANJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stratified train-test split\n",
        "\n",
        "# Train-test split\n",
        "# stratified on y because we have fewer bads than goods in both df1 and df2\n",
        "\n",
        "# df1\n",
        "x1 = df1.drop(columns=['Good'])\n",
        "y1 = df1['Good']\n",
        "\n",
        "x_train1, x_test1, y_train1, y_test1 = train_test_split(x1, y1, test_size=0.2, random_state=42, stratify=y1)\n",
        "\n",
        "# Check same proportions of 0s/1s in train and test\n",
        "proportion_df1 = pd.DataFrame({'y_train1': y_train1.value_counts(normalize=True), 'y_test1': y_test1.value_counts(normalize=True)})\n",
        "print(f\"Proportions for df1:\\n{proportion_df1}\\n\")\n",
        "\n",
        "# df2\n",
        "x2 = df2.drop(columns=['Good'])\n",
        "y2 = df2['Good']\n",
        "\n",
        "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.2, random_state=42, stratify=y2)\n",
        "\n",
        "# Check same proportions of 0s/1s in train and test\n",
        "proportion_df2 = pd.DataFrame({'y_train2': y_train2.value_counts(normalize=True), 'y_test2': y_test2.value_counts(normalize=True)})\n",
        "print(f\"Proportions for df2:\\n{proportion_df2}\\n\")\n",
        "\n",
        "# check\n",
        "print(f\"x_train1 shape: {x_train1.shape}\")\n",
        "print(f\"y_train1 shape: {y_train1.shape}\")\n",
        "print(f\"x_test1 shape: {x_test1.shape}\")\n",
        "print(f\"y_test1 shape: {y_test1.shape}\")\n",
        "print(f\"x_train2 shape: {x_train2.shape}\")\n",
        "print(f\"y_train2 shape: {y_train2.shape}\")\n",
        "print(f\"x_test2 shape: {x_test2.shape}\")\n",
        "print(f\"y_test2 shape: {y_test2.shape}\")"
      ],
      "metadata": {
        "id": "plFhnjjAnmeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3"
      ],
      "metadata": {
        "id": "pcXvLmmLzmtt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Feature selection using LASSO regression*\n",
        "\n",
        "Step 1:\n",
        "* Shortlist features with highest absolute coefficients at the optimal LASSO regression penalty for binning and Information Value analysis\n",
        "* Seeking features that have a high absolute coefficient and Information Value of >0.1\n",
        "\n"
      ],
      "metadata": {
        "id": "trak2AMw-sbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale numerical variables\n",
        "\n",
        "# Define MinMaxScaler for each subset\n",
        "scaler1 = MinMaxScaler()\n",
        "scaler2 = MinMaxScaler()\n",
        "\n",
        "# Scale only the numerical columns and replace in the original DataFrame\n",
        "x_train1[numerical_cols] = scaler1.fit_transform(x_train1[numerical_cols])\n",
        "x_train2[numerical_cols] = scaler2.fit_transform(x_train2[numerical_cols])\n",
        "\n",
        "# Fit test sets to MinMaxScale\n",
        "x_test1[numerical_cols] = scaler1.transform(x_test1[numerical_cols])\n",
        "x_test2[numerical_cols] = scaler2.transform(x_test2[numerical_cols])\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Px7B_hzL17FQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorical variables\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "x_train1_enc = pd.get_dummies(x_train1, columns=categorical_cols, drop_first=True)\n",
        "x_train2_enc = pd.get_dummies(x_train2, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "x_test1_enc = pd.get_dummies(x_test1, columns=categorical_cols, drop_first=True)\n",
        "x_test1_enc = x_test1.reindex(columns=x_train1_enc.columns, fill_value=0) # ensure train and test have the same columns to prevent errors when testing the fitted model\n",
        "x_test2_enc = pd.get_dummies(x_test2, columns=categorical_cols, drop_first=True)\n",
        "x_test2_enc = x_test2.reindex(columns=x_train2_enc.columns, fill_value=0) # ensure train and test have the same columns to prevent errors when testing the fitted model\n",
        "\n",
        "# Create list of names of encoded categorical columns\n",
        "categorical_cols_enc1 = [col for col in x_train1_enc.columns if col.startswith('q')]\n",
        "print(f\"Categorical columns x_train1: {categorical_cols_enc1}\")\n",
        "categorical_cols_enc1_ts = [col for col in x_test1_enc.columns if col.startswith('q')]\n",
        "print(f\"Categorical columns x_test1: {categorical_cols_enc1_ts}\")\n",
        "categorical_cols_enc2 = [col for col in x_train2_enc.columns if col.startswith('q')]\n",
        "print(f\"Categorical columns x_train2: {categorical_cols_enc2}\")\n",
        "categorical_cols_enc2_ts = [col for col in x_test2_enc.columns if col.startswith('q')]\n",
        "print(f\"Categorical columns x_test2: {categorical_cols_enc2_ts}\")"
      ],
      "metadata": {
        "id": "-1i_qK5O_AHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use LASSO regression to determine which variables are useful\n",
        "\n",
        "L1 = 0.1\n",
        "\n",
        "# df1\n",
        "reg = LassoCV()\n",
        "reg.fit(x_train1_enc, y_train1)\n",
        "coefs1 = pd.DataFrame({'feature': x_train1_enc.columns, 'coef1': reg.coef_})\n",
        "\n",
        "# df2\n",
        "reg.fit(x_train2_enc, y_train2)\n",
        "coefs2 = pd.DataFrame({'feature': x_train2_enc.columns, 'coef2': reg.coef_})\n",
        "\n",
        "# Merge coefficient results into one df\n",
        "coef_df = pd.merge(coefs1, coefs2, on='feature')\n",
        "\n",
        "# Sort\n",
        "coef_df.sort_values(by=['coef1', 'coef2'], ascending=False, inplace=True)"
      ],
      "metadata": {
        "id": "NDS6-Ijo_dfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot coefficients at optimal penalty\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add coef1\n",
        "fig.add_trace(go.Bar(x=coef_df['feature'],y=coef_df['coef1'], name='Coef 1',marker_color='blue'))\n",
        "\n",
        "# Add coef2\n",
        "fig.add_trace(go.Bar(x=coef_df['feature'],y=coef_df['coef2'],name='Coef 2',marker_color='orange'))\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Comparison of Coefficients',\n",
        "    xaxis_title='Feature', xaxis=dict(tickangle=45, tickmode='array'),\n",
        "    yaxis_title='Coefficient Value',\n",
        "    barmode='group', template='plotly_white', width=1200, height=500\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "EOdHkOQX_e7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Shortlist of variables for binning using coefficient threshold of >=abs(0.1)*\n",
        "\n",
        "* Numerical variables:\n",
        "    * x1 - Age, Duration\n",
        "    * x2 - Duration, Installp\n",
        "* Categorical variables:\n",
        "    * x1 - Checking_4, Coapp_3, Property_4\n",
        "    * x2 - Checking_4, Checking_3, Purpose_1, Coapp_3\n",
        "\n",
        "* Best 4 variables (in order):\n",
        "    * x1 - qChecking, qProperty, nDuration, qCoapp\n",
        "    * x2 - qChecking, nDuration, qPurpose, qCoapp\n",
        "\n"
      ],
      "metadata": {
        "id": "GZWgS9dYCDAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Binning numerical variables*"
      ],
      "metadata": {
        "id": "blqyCUuV_vS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numerical variables binning\n",
        "\n",
        "# Histogram of each shortlisted variable to identify potential bin thresholds\n",
        "\n",
        "# Reverse MinMax Scaling for interpretability of bin thresholds\n",
        "x_train1_fs = pd.DataFrame(scaler1.inverse_transform(x_train1[numerical_cols]), columns=x_train1[numerical_cols].columns, index=x_train1.index)\n",
        "x_train2_fs = pd.DataFrame(scaler2.inverse_transform(x_train2[numerical_cols]), columns=x_train2[numerical_cols].columns, index=x_train2.index)\n",
        "\n",
        "# Split data into Good and Bad for x_train1\n",
        "good_credit1 = x_train1_fs[y_train1 == 1]\n",
        "bad_credit1 = x_train1_fs[y_train1 == 0]\n",
        "\n",
        "# Split data into Good and Bad for x_train2\n",
        "good_credit2 = x_train2_fs[y_train2 == 1]\n",
        "bad_credit2 = x_train2_fs[y_train2 == 0]\n",
        "\n",
        "# Add goods for % calc\n",
        "x_train1_fs['Good'] = y_train1.values\n",
        "x_train2_fs['Good'] = y_train2.values\n",
        "\n",
        "# Plot histograms\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Create 3x2 subplots\n",
        "fig = make_subplots(rows=3, cols=2, subplot_titles=[\n",
        "    'nDuration Distribution (x_train1)',\n",
        "    'nAge Distribution (x_train1)',\n",
        "    'nDuration Distribution (x_train2)',\n",
        "    'nInstallp Distribution (x_train2)',\n",
        "    'nAmount Distribution (xtrain_2)',\n",
        "    'nInstallp Distribution (x_train1)'\n",
        "])\n",
        "\n",
        "# Plot 1: nDuration (x_train1)\n",
        "fig.add_trace(go.Histogram(x=good_credit1['nDuration'], name='Good Credit', marker_color='blue', opacity=0.5, xbins=dict(start=0, end=good_credit1['nDuration'].max()+1, size=1)), row=1, col=1)\n",
        "fig.add_trace(go.Histogram(x=bad_credit1['nDuration'], name='Bad Credit', marker_color='red', opacity=0.5, xbins=dict(start=0, end=bad_credit1['nDuration'].max()+1, size=1)), row=1, col=1)\n",
        "# Group by nDuration and calculate % of good applicants\n",
        "dur1_good_pct = x_train1_fs.groupby('nDuration')['Good'].mean() * 100\n",
        "fig.add_trace(go.Scatter(x=dur1_good_pct.index,y=dur1_good_pct.values,mode='lines+markers',name='% of Good Applicants', line=dict(color='blue'), marker=dict(size=6, color='blue')), row=1, col=1)\n",
        "\n",
        "# Plot 2: nAge (x_train1)\n",
        "fig.add_trace(go.Histogram(x=good_credit1['nAge'], name='Good Credit', marker_color='blue', opacity=0.5, xbins=dict(start=18, end=good_credit1['nAge'].max()+1, size=5)), row=1, col=2)\n",
        "fig.add_trace(go.Histogram(x=bad_credit1['nAge'], name='Bad Credit', marker_color='red', opacity=0.5, xbins=dict(start=18, end=bad_credit1['nAge'].max()+1, size=5)), row=1, col=2)\n",
        "# Group by nAge and calculate % of good applicants\n",
        "age_good_pct = x_train1_fs.groupby('nAge')['Good'].mean() * 100\n",
        "fig.add_trace(go.Scatter(x=age_good_pct.index,y=age_good_pct.values,mode='lines+markers',name='% of Good Applicants', line=dict(color='blue'), marker=dict(size=6, color='blue')), row=1, col=2)\n",
        "\n",
        "# Plot 3: nDuration (x_train2)\n",
        "fig.add_trace(go.Histogram(x=good_credit2['nDuration'], name='Good Credit', marker_color='blue', opacity=0.5, xbins=dict(start=10, end=good_credit2['nDuration'].max()+1, size=1)), row=2, col=1)\n",
        "fig.add_trace(go.Histogram(x=bad_credit2['nDuration'], name='Bad Credit', marker_color='red', opacity=0.5, xbins=dict(start=10, end=bad_credit2['nDuration'].max()+1, size=1)), row=2, col=1)\n",
        "# Group by nDuration and calculate % of good applicants\n",
        "dur2_good_pct = x_train2_fs.groupby('nDuration')['Good'].mean() * 100\n",
        "fig.add_trace(go.Scatter(x=dur2_good_pct.index,y=dur2_good_pct.values,mode='lines+markers',name='% of Good Applicants', line=dict(color='blue'), marker=dict(size=6, color='blue')), row=2, col=1)\n",
        "\n",
        "# Plot 4: nInstallp (x_train2)\n",
        "fig.add_trace(go.Histogram(x=good_credit2['nInstallp'], name='Good Credit', marker_color='blue', opacity=0.5, xbins=dict(start=0, end=good_credit2['nInstallp'].max()+1, size=1)), row=2, col=2)\n",
        "fig.add_trace(go.Histogram(x=bad_credit2['nInstallp'], name='Bad Credit', marker_color='red', opacity=0.5, xbins=dict(start=0, end=bad_credit2['nInstallp'].max()+1, size=1)), row=2, col=2)\n",
        "# Group by nInstallp and calculate % of good applicants\n",
        "inst_good_pct = x_train2_fs.groupby('nInstallp')['Good'].mean() * 100\n",
        "fig.add_trace(go.Scatter(x=inst_good_pct.index,y=inst_good_pct.values,mode='lines+markers',name='% of Good Applicants', line=dict(color='blue'), marker=dict(size=6, color='blue')), row=2, col=2)\n",
        "\n",
        "# Plot 5: nAmount (x_train2)\n",
        "fig.add_trace(go.Histogram(x=good_credit2['nAmount'], name='Good Credit', marker_color='blue', opacity=0.5, xbins=dict(start=0, end=good_credit2['nAmount'].max()+1, size=2500)), row=3, col=1)\n",
        "fig.add_trace(go.Histogram(x=bad_credit2['nAmount'], name='Bad Credit', marker_color='red', opacity=0.5, xbins=dict(start=0, end=bad_credit2['nAmount'].max()+1, size=2500)), row=3, col=1)\n",
        "# Group by nInstallp and calculate % of good applicants\n",
        "#inst_good_pct = x_train2_fs.groupby('nAmount')['Good'].mean() * 100\n",
        "#fig.add_trace(go.Scatter(x=inst_good_pct.index,y=inst_good_pct.values,mode='lines+markers',name='% of Good Applicants', line=dict(color='blue'), marker=dict(size=6, color='blue')), row=3, col=1)\n",
        "\n",
        "# Plot 5: nInstallp (x_train1)\n",
        "fig.add_trace(go.Histogram(x=good_credit1['nInstallp'], name='Good Credit', marker_color='blue', opacity=0.5, xbins=dict(start=0, end=good_credit1['nInstallp'].max()+1, size=1)), row=3, col=2)\n",
        "fig.add_trace(go.Histogram(x=bad_credit1['nInstallp'], name='Bad Credit', marker_color='red', opacity=0.5, xbins=dict(start=0, end=bad_credit1['nInstallp'].max()+1, size=1)), row=3, col=2)\n",
        "\n",
        "# Group by nInstallp and calculate % of good applicants\n",
        "inst_good_pct = x_train1_fs.groupby('nInstallp')['Good'].mean() * 100\n",
        "fig.add_trace(go.Scatter(x=inst_good_pct.index, y=inst_good_pct.values, mode='lines+markers', name='% of Good Applicants', line=dict(color='blue'), marker=dict(size=6, color='blue')), row=3, col=2)\n",
        "\n",
        "\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Numerical variables - good/bad distributions',\n",
        "    barmode='overlay',\n",
        "    width=900,\n",
        "    height=700,\n",
        "    template='plotly_white',\n",
        "    showlegend=True\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# x1 Duration - 5 bins 4-5, 6-7, 8-9, 10-11, 12; 3 bins 4-7, 8-11, 12\n",
        "# x1 Age - decades - 5 bins 19-29, 30-39, 40-49, 50-59, 60+ ;\n",
        "# x2 Duration - longer is higher risk - 4 c12 month bins 13-24, 25-36, 37-48, 49+ or 13-23, 24-35, 36-47, 48+\n",
        "# x2 Installp - 1+2 vs. 3+4, 1+2+3 vs. 4\n",
        "# x2 nAmount - 0-5k, 5-10k, >10k\n"
      ],
      "metadata": {
        "id": "V51gRiKh9XQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Work out the best binning option for each variable and calculate the WOE and IV of each bin"
      ],
      "metadata": {
        "id": "NhcdFGFVeNyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 binning options for x_train1['nDuration']\n",
        "\n",
        "# Decision - x1_dur_o2 - 3 buckets - good IV of 0.3 and 5 buckets IV of 0.843 is possibly over-predicting\n",
        "\n",
        "ep = 1e-6\n",
        "\n",
        "#################################\n",
        "# x1_dur_o1\n",
        "#################################\n",
        "bins = [0, 11, 12]  # Define the bin edges\n",
        "labels = ['4-11 mnth', '12 mnth']  # Labels for the bins\n",
        "\n",
        "# Bin the 'nDuration' values\n",
        "x_train1_fs['nDuration_bin'] = pd.cut(x_train1_fs['nDuration'], bins=bins, labels=labels, right=True)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x1_dur_o1 = pd.crosstab(x_train1_fs['nDuration_bin'], x_train1_fs['Good'], dropna=False).reset_index()\n",
        "x1_dur_o1.columns = ['Bin', 'Bads', 'Goods']\n",
        "x1_dur_o1 = x1_dur_o1[['Bin','Goods','Bads', ]] # re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x1_dur_o1['Good%'] = x1_dur_o1['Goods'] / x1_dur_o1['Goods'].sum()\n",
        "x1_dur_o1['Bad%'] = x1_dur_o1['Bads'] / x1_dur_o1['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x1_dur_o1['WOE'] = np.log(x1_dur_o1['Good%'] / x1_dur_o1['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x1_dur_o1['IV'] = (x1_dur_o1['Good%'] - x1_dur_o1['Bad%']) * x1_dur_o1['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV = x1_dur_o1['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x1_dur_o1)\n",
        "print(f\"Total IV: {total_IV}\")\n",
        "\n",
        "#################################\n",
        "# x1_dur_o2\n",
        "#################################\n",
        "bins_x1dur2 = [0, 7, 11, 12]  # Define the bin edges\n",
        "labels_x1dur2 = ['4-7','8-11', '12']  # Labels for the bins\n",
        "\n",
        "# Bin the 'nDuration' values\n",
        "x_train1_fs['nDuration_bin'] = pd.cut(x_train1_fs['nDuration'], bins=bins_x1dur2, labels=labels_x1dur2, right=True)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x1_dur_o2 = pd.crosstab(x_train1_fs['nDuration_bin'], x_train1_fs['Good'], dropna=False).reset_index()\n",
        "x1_dur_o2.columns = ['Bin', 'Bads', 'Goods']\n",
        "x1_dur_o2 = x1_dur_o2[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x1_dur_o2['Good%'] = x1_dur_o2['Goods'] / x1_dur_o2['Goods'].sum()\n",
        "x1_dur_o2['Bad%'] = x1_dur_o2['Bads'] / x1_dur_o2['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x1_dur_o2['WOE'] = np.log(x1_dur_o2['Good%'] / x1_dur_o2['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x1_dur_o2['IV'] = (x1_dur_o2['Good%'] - x1_dur_o2['Bad%']) * x1_dur_o2['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV = x1_dur_o2['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x1_dur_o2)\n",
        "print(f\"Total IV: {total_IV}\")\n",
        "\n",
        "#################################\n",
        "# x1_dur_o3\n",
        "#################################\n",
        "bins = [0, 5, 7, 9, 11, 12]  # Define the bin edges\n",
        "labels = ['4-5 mnth','6-7 mnth', '8-9 mnth', '10-11 mnth', '12 mnth']  # Labels for the bins\n",
        "\n",
        "# Bin the 'nDuration' values\n",
        "x_train1_fs['nDuration_bin'] = pd.cut(x_train1_fs['nDuration'], bins=bins, labels=labels, right=True)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x1_dur_o3 = pd.crosstab(x_train1_fs['nDuration_bin'], x_train1_fs['Good'], dropna=False).reset_index()\n",
        "x1_dur_o3.columns = ['Bin', 'Bads', 'Goods']\n",
        "x1_dur_o3 = x1_dur_o3[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x1_dur_o3['Good%'] = (x1_dur_o3['Goods']+ep) / x1_dur_o3['Goods'].sum()\n",
        "x1_dur_o3['Bad%'] = (x1_dur_o3['Bads']+ep) / x1_dur_o3['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x1_dur_o3['WOE'] = np.log(x1_dur_o3['Good%'] / x1_dur_o3['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x1_dur_o3['IV'] = (x1_dur_o3['Good%'] - x1_dur_o3['Bad%']) * x1_dur_o3['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV = x1_dur_o3['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x1_dur_o3)\n",
        "print(f\"Total IV: {total_IV}\")\n"
      ],
      "metadata": {
        "id": "MAJqd82PeNwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# binning of x_train1['nAge']\n",
        "\n",
        "# Decision - only include if categorical variables have less good IVs than 0.21\n",
        "\n",
        "bins = [0, 30, 40, 50, 60, np.inf]\n",
        "labels = ['19-29', '30-39', '40-49', '50-59', '60+']\n",
        "\n",
        "# Bin the 'nAge' values\n",
        "x_train1_fs['nAge_bin'] = pd.cut(x_train1_fs['nAge'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x1_age = pd.crosstab(x_train1_fs['nAge_bin'], x_train1_fs['Good'], dropna=False).reset_index()\n",
        "x1_age.columns = ['Bin', 'Bads', 'Goods']\n",
        "x1_age = x1_age[['Bin', 'Goods', 'Bads']]  # re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x1_age['Good%'] = (x1_age['Goods'] + ep) / (x1_age['Goods'].sum() + ep)\n",
        "x1_age['Bad%'] = (x1_age['Bads'] + ep) / (x1_age['Bads'].sum() + ep)\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x1_age['WOE'] = np.log(x1_age['Good%'] / x1_age['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x1_age['IV'] = (x1_age['Good%'] - x1_age['Bad%']) * x1_age['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV = x1_age['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x1_age)\n",
        "print(f\"Total IV: {total_IV}\")\n"
      ],
      "metadata": {
        "id": "9OmvMBeNeNtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interestingly, IV of Installp for subset 1 is much stronger despite LASSO regression results - 0.22. This is a better IV than age but with fewer buckets.\n",
        "\n",
        "# Decision - potentially use option 3 of this feature if other categorical variables have lower IVs.\n",
        "\n",
        "#################################\n",
        "# x1_installp_o1\n",
        "#################################\n",
        "# Option 1: Bin edges [0, 2, np.inf]\n",
        "bins_o1 = [0, 2, np.inf]\n",
        "labels_o1 = ['0-2 Installp', '3+ Installp']\n",
        "\n",
        "# Bin the 'nInstallp' values\n",
        "x_train1_fs['nInstallp_bin'] = pd.cut(x_train1_fs['nInstallp'], bins=bins_o1, labels=labels_o1, right=True)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x1_installp_o1 = pd.crosstab(x_train1_fs['nInstallp_bin'], x_train1_fs['Good'], dropna=False).reset_index()\n",
        "x1_installp_o1.columns = ['Bin', 'Bads', 'Goods']\n",
        "x1_installp_o1 = x1_installp_o1[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x1_installp_o1['Good%'] = x1_installp_o1['Goods'] / x1_installp_o1['Goods'].sum()\n",
        "x1_installp_o1['Bad%'] = x1_installp_o1['Bads'] / x1_installp_o1['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x1_installp_o1['WOE'] = np.log(x1_installp_o1['Good%'] / x1_installp_o1['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x1_installp_o1['IV'] = (x1_installp_o1['Good%'] - x1_installp_o1['Bad%']) * x1_installp_o1['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_o1 = x1_installp_o1['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x1_installp_o1)\n",
        "print(f\"Total IV for x1_installp_o1: {total_IV_o1}\")\n",
        "\n",
        "\n",
        "#################################\n",
        "# x1_installp_o2\n",
        "#################################\n",
        "# Option 2: Bin edges [0, 3, np.inf]\n",
        "bins_o2 = [0, 3, np.inf]\n",
        "labels_o2 = ['0-3 Installp', '4+ Installp']\n",
        "\n",
        "# Bin the 'nInstallp' values\n",
        "x_train1_fs['nInstallp_bin'] = pd.cut(x_train1_fs['nInstallp'], bins=bins_o2, labels=labels_o2, right=True)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x1_installp_o2 = pd.crosstab(x_train1_fs['nInstallp_bin'], x_train1_fs['Good'], dropna=False).reset_index()\n",
        "x1_installp_o2.columns = ['Bin', 'Bads', 'Goods']\n",
        "x1_installp_o2 = x1_installp_o2[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x1_installp_o2['Good%'] = x1_installp_o2['Goods'] / x1_installp_o2['Goods'].sum()\n",
        "x1_installp_o2['Bad%'] = x1_installp_o2['Bads'] / x1_installp_o2['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x1_installp_o2['WOE'] = np.log(x1_installp_o2['Good%'] / x1_installp_o2['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x1_installp_o2['IV'] = (x1_installp_o2['Good%'] - x1_installp_o2['Bad%']) * x1_installp_o2['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_o2 = x1_installp_o2['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x1_installp_o2)\n",
        "print(f\"Total IV for x1_installp_o2: {total_IV_o2}\")\n",
        "\n",
        "\n",
        "#################################\n",
        "# x1_installp_o3\n",
        "#################################\n",
        "# Option 3: Bin edges [0, 2, 3, np.inf]\n",
        "bins_o3 = [0, 2, 3, np.inf]\n",
        "labels_o3 = ['0-2', '3', '4+']\n",
        "\n",
        "# Bin the 'nInstallp' values\n",
        "x_train1_fs['nInstallp_bin'] = pd.cut(x_train1_fs['nInstallp'], bins=bins_o3, labels=labels_o3, right=True)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x1_installp_o3 = pd.crosstab(x_train1_fs['nInstallp_bin'], x_train1_fs['Good'], dropna=False).reset_index()\n",
        "x1_installp_o3.columns = ['Bin', 'Bads', 'Goods']\n",
        "x1_installp_o3 = x1_installp_o3[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x1_installp_o3['Good%'] = x1_installp_o3['Goods'] / x1_installp_o3['Goods'].sum()\n",
        "x1_installp_o3['Bad%'] = x1_installp_o3['Bads'] / x1_installp_o3['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x1_installp_o3['WOE'] = np.log(x1_installp_o3['Good%'] / x1_installp_o3['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x1_installp_o3['IV'] = (x1_installp_o3['Good%'] - x1_installp_o3['Bad%']) * x1_installp_o3['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_o3 = x1_installp_o3['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x1_installp_o3)\n",
        "print(f\"Total IV for x1_installp_o3: {total_IV_o3}\")\n"
      ],
      "metadata": {
        "id": "T1uwwflKwtLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# binning of x_train2['nDuration']\n",
        "\n",
        "# 2 binning options considered\n",
        "\n",
        "# Decision - option 2 - better IV at 0.12\n",
        "\n",
        "#################################\n",
        "# x2_dur_o1\n",
        "#################################\n",
        "bins = [0, 24, 36, 48, np.inf]\n",
        "labels = ['13-24 mnth', '25-36 mnth', '37-48 mnth', '49+ mnth']\n",
        "\n",
        "# Bin the 'nDuration' values\n",
        "x_train2_fs['nDuration_bin'] = pd.cut(x_train2_fs['nDuration'], bins=bins, labels=labels, right=True)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x2_dur_o1 = pd.crosstab(x_train2_fs['nDuration_bin'], x_train2_fs['Good'], dropna=False).reset_index()\n",
        "x2_dur_o1.columns = ['Bin', 'Bads', 'Goods']\n",
        "x2_dur_o1 = x2_dur_o1[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x2_dur_o1['Good%'] = x2_dur_o1['Goods'] / x2_dur_o1['Goods'].sum()\n",
        "x2_dur_o1['Bad%'] = x2_dur_o1['Bads'] / x2_dur_o1['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x2_dur_o1['WOE'] = np.log(x2_dur_o1['Good%'] / x2_dur_o1['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x2_dur_o1['IV'] = (x2_dur_o1['Good%'] - x2_dur_o1['Bad%']) * x2_dur_o1['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_o1 = x2_dur_o1['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x2_dur_o1)\n",
        "print(f\"Total IV for x2_dur_o1: {total_IV_o1}\")\n",
        "\n",
        "#################################\n",
        "# x2_dur_o2\n",
        "#################################\n",
        "bins_dur2 = [0, 23, 35, 47, np.inf]\n",
        "labels_dur2 = ['13-23', '24-35', '36-47', '48+']\n",
        "\n",
        "# Bin the 'nDuration' values\n",
        "x_train2_fs['nDuration_bin'] = pd.cut(x_train2_fs['nDuration'], bins=bins_dur2, labels=labels_dur2, right=True)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x2_dur_o2 = pd.crosstab(x_train2_fs['nDuration_bin'], x_train2_fs['Good'], dropna=False).reset_index()\n",
        "x2_dur_o2.columns = ['Bin', 'Bads', 'Goods']\n",
        "x2_dur_o2 = x2_dur_o2[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x2_dur_o2['Good%'] = x2_dur_o2['Goods'] / x2_dur_o2['Goods'].sum()\n",
        "x2_dur_o2['Bad%'] = x2_dur_o2['Bads'] / x2_dur_o2['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x2_dur_o2['WOE'] = np.log(x2_dur_o2['Good%'] / x2_dur_o2['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x2_dur_o2['IV'] = (x2_dur_o2['Good%'] - x2_dur_o2['Bad%']) * x2_dur_o2['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_o2 = x2_dur_o2['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x2_dur_o2)\n",
        "print(f\"Total IV for x2_dur_o2: {total_IV_o2}\")\n"
      ],
      "metadata": {
        "id": "pc1VJDRkeNnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x2\n",
        "# Installp\n",
        "\n",
        "# 3 binning options considered\n",
        "\n",
        "# Decision - don't use this feature: as suspected from histogram, very low information value\n",
        "\n",
        "#################################\n",
        "# x2_installp_o1\n",
        "#################################\n",
        "# Option 1: Bin edges [0, 2, np.inf]\n",
        "bins_o1 = [0, 2, np.inf]\n",
        "labels_o1 = ['0-2 Installp', '3+ Installp']\n",
        "\n",
        "# Bin the 'nInstallp' values\n",
        "x_train2_fs['nInstallp_bin'] = pd.cut(x_train2_fs['nInstallp'], bins=bins_o1, labels=labels_o1, right=True)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x2_installp_o1 = pd.crosstab(x_train2_fs['nInstallp_bin'], x_train2_fs['Good'], dropna=False).reset_index()\n",
        "x2_installp_o1.columns = ['Bin', 'Bads', 'Goods']\n",
        "x2_installp_o1 = x2_installp_o1[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x2_installp_o1['Good%'] = x2_installp_o1['Goods'] / x2_installp_o1['Goods'].sum()\n",
        "x2_installp_o1['Bad%'] = x2_installp_o1['Bads'] / x2_installp_o1['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x2_installp_o1['WOE'] = np.log(x2_installp_o1['Good%'] / x2_installp_o1['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x2_installp_o1['IV'] = (x2_installp_o1['Good%'] - x2_installp_o1['Bad%']) * x2_installp_o1['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_o1 = x2_installp_o1['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x2_installp_o1)\n",
        "print(f\"Total IV for x2_installp_o1: {total_IV_o1}\")\n",
        "\n",
        "\n",
        "#################################\n",
        "# x2_installp_o2\n",
        "#################################\n",
        "# Option 2: Bin edges [0, 3, np.inf]\n",
        "bins_o2 = [0, 3, np.inf]\n",
        "labels_o2 = ['0-3 Installp', '4+ Installp']\n",
        "\n",
        "# Bin the 'nInstallp' values\n",
        "x_train2_fs['nInstallp_bin'] = pd.cut(x_train2_fs['nInstallp'], bins=bins_o2, labels=labels_o2, right=True)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x2_installp_o2 = pd.crosstab(x_train2_fs['nInstallp_bin'], x_train2_fs['Good'], dropna=False).reset_index()\n",
        "x2_installp_o2.columns = ['Bin', 'Bads', 'Goods']\n",
        "x2_installp_o2 = x2_installp_o2[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x2_installp_o2['Good%'] = x2_installp_o2['Goods'] / x2_installp_o2['Goods'].sum()\n",
        "x2_installp_o2['Bad%'] = x2_installp_o2['Bads'] / x2_installp_o2['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x2_installp_o2['WOE'] = np.log(x2_installp_o2['Good%'] / x2_installp_o2['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x2_installp_o2['IV'] = (x2_installp_o2['Good%'] - x2_installp_o2['Bad%']) * x2_installp_o2['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_o2 = x2_installp_o2['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x2_installp_o2)\n",
        "print(f\"Total IV for x2_installp_o2: {total_IV_o2}\")\n",
        "\n",
        "\n",
        "#################################\n",
        "# x2_installp_o3\n",
        "#################################\n",
        "# Option 3: Bin edges [0, 2, 3, np.inf]\n",
        "bins_o3 = [0, 2, 3, np.inf]\n",
        "labels_o3 = ['0-2 Installp', '3 Installp', '4+ Installp']\n",
        "\n",
        "# Bin the 'nInstallp' values\n",
        "x_train2_fs['nInstallp_bin'] = pd.cut(x_train2_fs['nInstallp'], bins=bins_o3, labels=labels_o3, right=True)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x2_installp_o3 = pd.crosstab(x_train2_fs['nInstallp_bin'], x_train2_fs['Good'], dropna=False).reset_index()\n",
        "x2_installp_o3.columns = ['Bin', 'Bads', 'Goods']\n",
        "x2_installp_o3 = x2_installp_o3[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x2_installp_o3['Good%'] = x2_installp_o3['Goods'] / x2_installp_o3['Goods'].sum()\n",
        "x2_installp_o3['Bad%'] = x2_installp_o3['Bads'] / x2_installp_o3['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x2_installp_o3['WOE'] = np.log(x2_installp_o3['Good%'] / x2_installp_o3['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x2_installp_o3['IV'] = (x2_installp_o3['Good%'] - x2_installp_o3['Bad%']) * x2_installp_o3['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_o3 = x2_installp_o3['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x2_installp_o3)\n",
        "print(f\"Total IV for x2_installp_o3: {total_IV_o3}\")\n"
      ],
      "metadata": {
        "id": "SxaGkHx2eNkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x2\n",
        "# nAmount\n",
        "\n",
        "# 2 binning options considered\n",
        "# Decision - don't use this feature - IV <0.1\n",
        "\n",
        "\n",
        "# Option 1: 0-5k, 5-10k, >10k - IV = 0.05\n",
        "bins_am = [0, 5000, 10000, np.inf]\n",
        "labels_am = ['<=5k', '5-10k', '>10k']\n",
        "\n",
        "# Bin the 'nAmount' values\n",
        "x_train2_fs['nAmount_bin'] = pd.cut(x_train2_fs['nAmount'], bins=bins_am, labels=labels_am, right=True)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x2_amount_o1 = pd.crosstab(x_train2_fs['nAmount_bin'], x_train2_fs['Good'], dropna=False).reset_index()\n",
        "x2_amount_o1.columns = ['Bin', 'Bads', 'Goods']\n",
        "x2_amount_o1 = x2_amount_o1[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x2_amount_o1['Good%'] = x2_amount_o1['Goods'] / x2_amount_o1['Goods'].sum()\n",
        "x2_amount_o1['Bad%'] = x2_amount_o1['Bads'] / x2_amount_o1['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x2_amount_o1['WOE'] = np.log(x2_amount_o1['Good%'] / x2_amount_o1['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x2_amount_o1['IV'] = (x2_amount_o1['Good%'] - x2_amount_o1['Bad%']) * x2_amount_o1['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_o1 = x2_amount_o1['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x2_amount_o1)\n",
        "print(f\"Total IV for x2_amount_o1: {total_IV_o1}\")\n",
        "\n",
        "\n",
        "# Option 2: 0-2.5k, 2.5-5k 5-10k, >10k - IV = 0.08\n",
        "bins_am2 = [0, 2500, 5000, 10000, np.inf]\n",
        "labels_am2 = ['<=2.5k', '2.5-5k', '5-10k', '>10k']\n",
        "\n",
        "# Bin the 'nAmount' values\n",
        "x_train2_fs['nAmount_bin'] = pd.cut(x_train2_fs['nAmount'], bins=bins_am2, labels=labels_am2, right=True)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x2_amount_o2 = pd.crosstab(x_train2_fs['nAmount_bin'], x_train2_fs['Good'], dropna=False).reset_index()\n",
        "x2_amount_o2.columns = ['Bin', 'Bads', 'Goods']\n",
        "x2_amount_o2 = x2_amount_o2[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x2_amount_o2['Good%'] = x2_amount_o2['Goods'] / x2_amount_o2['Goods'].sum()\n",
        "x2_amount_o2['Bad%'] = x2_amount_o2['Bads'] / x2_amount_o2['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x2_amount_o2['WOE'] = np.log(x2_amount_o2['Good%'] / x2_amount_o2['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x2_amount_o2['IV'] = (x2_amount_o2['Good%'] - x2_amount_o2['Bad%']) * x2_amount_o2['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_o2 = x2_amount_o2['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x2_amount_o2)\n",
        "print(f\"Total IV for x2_amount_o2: {total_IV_o2}\")"
      ],
      "metadata": {
        "id": "Vd744ucpN5Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Summary of numerical variables*\n",
        "\n",
        "* Subset 1:\n",
        "    * Use nDuration in 3 buckets - IV = 0.3\n",
        "    * Potentially use nInstallp in 3 buckets too - IV = 0.22\n",
        "* Subset 2:\n",
        "    * Use nDuration in 4 buckets - IV = 0.12"
      ],
      "metadata": {
        "id": "AX57DPXUyx8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Binning categorical variables*\n",
        "\n",
        "* x1 - Checking_4, Coapp_3, Property_4\n",
        "* x2 - Checking_4, Checking_3, Purpose_1, Coapp_3"
      ],
      "metadata": {
        "id": "aGNC67_gQ-ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise volumes and % Good in each shortlisted feature\n",
        "\n",
        "# Add goods for % calc\n",
        "x_train1['Good'] = y_train1.values\n",
        "x_train2['Good'] = y_train2.values\n",
        "\n",
        "# Create a bar plot for 'qChecking'\n",
        "qChecking_counts = x_train1['qChecking'].value_counts().reset_index()\n",
        "qChecking_counts.columns = ['Category', 'Count']\n",
        "\n",
        "# Create a bar plot for 'qCoapp'\n",
        "qCoapp_counts = x_train1['qCoapp'].value_counts().reset_index()\n",
        "qCoapp_counts.columns = ['Category', 'Count']\n",
        "\n",
        "# Create a bar plot for 'qProperty'\n",
        "qProperty_counts = x_train1['qProperty'].value_counts().reset_index()\n",
        "qProperty_counts.columns = ['Category', 'Count']\n",
        "\n",
        "# Create the bar graph for all three variables\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add bar for qChecking\n",
        "fig.add_trace(go.Bar(x=qChecking_counts['Category'],y=qChecking_counts['Count'],name='qChecking',marker=dict(color='blue')\n",
        "))\n",
        "chk_good_pct = x_train1.groupby('qChecking')['Good'].mean() * 100\n",
        "fig.add_trace(go.Scatter(x=chk_good_pct.index,y=chk_good_pct.values,mode='lines+markers',name='% of Good Checking', line=dict(color='blue'), marker=dict(size=6, color='blue')))\n",
        "\n",
        "# Add bar for qCoapp\n",
        "fig.add_trace(go.Bar(x=qCoapp_counts['Category'],y=qCoapp_counts['Count'],name='qCoapp',marker=dict(color='green')\n",
        "))\n",
        "coap_good_pct = x_train1.groupby('qCoapp')['Good'].mean() * 100\n",
        "fig.add_trace(go.Scatter(x=coap_good_pct.index,y=coap_good_pct.values,mode='lines+markers',name='% of Good Coap', line=dict(color='green'), marker=dict(size=6, color='green')))\n",
        "\n",
        "# Add bar for qProperty\n",
        "fig.add_trace(go.Bar(x=qProperty_counts['Category'],y=qProperty_counts['Count'],name='qProperty',marker=dict(color='red')\n",
        "))\n",
        "prop_good_pct = x_train1.groupby('qProperty')['Good'].mean() * 100\n",
        "fig.add_trace(go.Scatter(x=prop_good_pct.index,y=prop_good_pct.values,mode='lines+markers',name='% of Good Coap', line=dict(color='red'), marker=dict(size=6, color='red')))\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Volume of Applicants and % of Goods by Category - subset 1 only',\n",
        "    barmode='group',\n",
        "    xaxis_title='Category',\n",
        "    yaxis_title='Volume of Applicants',\n",
        "    template='plotly_white'  # You can change the template for the look of the plot\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n",
        "\n",
        "# Checking - keep as 4 buckets (clear difference in % goods in each bucket and logical difference between buckets)\n",
        "# Coap - 1+2 vs. 3 (logical grouping of no guarentor vs. guarentor reflected in % of goods)\n",
        "# Property 1, 2+3, 4 (real estate, other collateral, unknown - logical grouping and reflected in % of goods)"
      ],
      "metadata": {
        "id": "Sgc5-Jis6YOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x1 Checking\n",
        "#################################\n",
        "\n",
        "# Keeping original categories\n",
        "# IV = 0.65, but this is expected for this variable\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x1_checking = pd.crosstab(x_train1['qChecking'], x_train1['Good'], dropna=False).reset_index()\n",
        "x1_checking.columns = ['Bin', 'Bads', 'Goods']\n",
        "x1_checking = x1_checking[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x1_checking['Good%'] = x1_checking['Goods'] / x1_checking['Goods'].sum()\n",
        "x1_checking['Bad%'] = x1_checking['Bads'] / x1_checking['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x1_checking['WOE'] = np.log(x1_checking['Good%'] / x1_checking['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x1_checking['IV'] = (x1_checking['Good%'] - x1_checking['Bad%']) * x1_checking['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_chk = x1_checking['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x1_checking)\n",
        "print(f\"Total IV for x1_checking: {total_IV_chk}\")"
      ],
      "metadata": {
        "id": "--blL7KlC5Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x1 Coapp\n",
        "\n",
        "# 2 bins - very high IV 0.87 but expected\n",
        "\n",
        "# Bins\n",
        "bins_coapp1 = [0, 2, np.inf]\n",
        "labels_coapp1 = ['No Gurantor', 'Guarantor']\n",
        "\n",
        "# Bin the 'nCoapp' values\n",
        "x_train1['qCoapp_bin'] = pd.cut(x_train1['qCoapp'], bins=bins_coapp1, labels=labels_coapp1, right=True)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x1_coap = pd.crosstab(x_train1['qCoapp_bin'], x_train1['Good'], dropna=False).reset_index()\n",
        "x1_coap.columns = ['Bin', 'Bads', 'Goods']\n",
        "x1_coap = x1_coap[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x1_coap['Good%'] = x1_coap['Goods'] / x1_coap['Goods'].sum()\n",
        "x1_coap['Bad%'] = (x1_coap['Bads']+ep) / x1_coap['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x1_coap['WOE'] = np.log(x1_coap['Good%'] / x1_coap['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x1_coap['IV'] = (x1_coap['Good%'] - x1_coap['Bad%']) * x1_coap['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_coap = x1_coap['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x1_coap)\n",
        "print(f\"Total IV for x1_coap: {total_IV_coap}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Zrqj-Pqs16yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x1 Property\n",
        "\n",
        "# Good IV of 0.28\n",
        "\n",
        "# Bins\n",
        "bins_prop1 = [0, 1, 3, np.inf]\n",
        "labels_prop1 = ['Real_estate', 'Other_collat', 'Unk_Na']\n",
        "\n",
        "# Bin the 'qProperty' values\n",
        "x_train1['qProp_bin'] = pd.cut(x_train1['qProperty'], bins=bins_prop1, labels=labels_prop1, right=True)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x1_prop = pd.crosstab(x_train1['qProp_bin'], x_train1['Good'], dropna=False).reset_index()\n",
        "x1_prop.columns = ['Bin', 'Bads', 'Goods']\n",
        "x1_prop = x1_prop[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x1_prop['Good%'] = x1_prop['Goods'] / x1_prop['Goods'].sum()\n",
        "x1_prop['Bad%'] = (x1_prop['Bads'] + ep) / x1_prop['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x1_prop['WOE'] = np.log(x1_prop['Good%'] / x1_prop['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x1_prop['IV'] = (x1_prop['Good%'] - x1_prop['Bad%']) * x1_prop['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_prop = x1_prop['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x1_prop)\n",
        "print(f\"Total IV for x1_prop: {total_IV_prop}\")"
      ],
      "metadata": {
        "id": "TbYqtw8yn7dE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*x2*"
      ],
      "metadata": {
        "id": "q9zr-imGEenT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise volumes and % Good in each shortlisted feature\n",
        "\n",
        "# Add goods for % calc\n",
        "x_train1['Good'] = y_train1.values\n",
        "x_train2['Good'] = y_train2.values\n",
        "\n",
        "# Create a bar plot for 'qChecking'\n",
        "qChecking_counts = x_train2['qChecking'].value_counts().reset_index()\n",
        "qChecking_counts.columns = ['Category', 'Count']\n",
        "\n",
        "# Create a bar plot for 'qCoapp'\n",
        "qCoapp_counts = x_train2['qCoapp'].value_counts().reset_index()\n",
        "qCoapp_counts.columns = ['Category', 'Count']\n",
        "\n",
        "# Create a bar plot for 'qPurpose'\n",
        "qPurpose_counts = x_train2['qPurpose'].value_counts().reset_index()\n",
        "qPurpose_counts.columns = ['Category', 'Count']\n",
        "\n",
        "# Create a bar plot for 'qEmployed'\n",
        "qEmployed_counts = x_train2['qEmployed'].value_counts().reset_index()\n",
        "qEmployed_counts.columns = ['Category', 'Count']\n",
        "\n",
        "# Create a bar plot for 'qSavings'\n",
        "qSavings_counts = x_train2['qSavings'].value_counts().reset_index()\n",
        "qSavings_counts.columns = ['Category', 'Count']\n",
        "\n",
        "# Create the bar graph for all three variables\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add bar for qChecking\n",
        "fig.add_trace(go.Bar(x=qChecking_counts['Category'], y=qChecking_counts['Count'], name='qChecking', marker=dict(color='blue')))\n",
        "chk_good_pct = x_train2.groupby('qChecking')['Good'].mean() * 100\n",
        "fig.add_trace(go.Scatter(x=chk_good_pct.index, y=chk_good_pct.values, mode='lines+markers', name='% of Good Checking', line=dict(color='blue'), marker=dict(size=6, color='blue')))\n",
        "\n",
        "# Add bar for qCoapp\n",
        "fig.add_trace(go.Bar(x=qCoapp_counts['Category'], y=qCoapp_counts['Count'], name='qCoapp', marker=dict(color='green')))\n",
        "coap_good_pct = x_train2.groupby('qCoapp')['Good'].mean() * 100\n",
        "fig.add_trace(go.Scatter(x=coap_good_pct.index, y=coap_good_pct.values, mode='lines+markers', name='% of Good Coap', line=dict(color='green'), marker=dict(size=6, color='green')))\n",
        "\n",
        "# Add bar for qPurpose\n",
        "fig.add_trace(go.Bar(x=qPurpose_counts['Category'], y=qPurpose_counts['Count'], name='qPurpose', marker=dict(color='red')))\n",
        "purp_good_pct = x_train2.groupby('qPurpose')['Good'].mean() * 100\n",
        "fig.add_trace(go.Scatter(x=purp_good_pct.index, y=purp_good_pct.values, mode='lines+markers', name='% of Good Purpose', line=dict(color='red'), marker=dict(size=6, color='red')))\n",
        "\n",
        "# Add bar for qEmployed\n",
        "fig.add_trace(go.Bar(x=qEmployed_counts['Category'],y=qEmployed_counts['Count'],name='qEmployed',marker=dict(color='purple')))\n",
        "emp_good_pct = x_train2.groupby('qEmployed')['Good'].mean() * 100\n",
        "fig.add_trace(go.Scatter(x=emp_good_pct.index,y=emp_good_pct.values,mode='lines+markers',name='% of Good Employed',line=dict(color='purple'),marker=dict(size=6, color='purple')))\n",
        "\n",
        "# Add qSavings\n",
        "fig.add_trace(go.Bar(x=qSavings_counts['Category'], y=qSavings_counts['Count'], name='qSavings', marker=dict(color='orange')))\n",
        "sav_good_pct = x_train2.groupby('qSavings')['Good'].mean() * 100\n",
        "fig.add_trace(go.Scatter(x=sav_good_pct.index, y=sav_good_pct.values, mode='lines+markers', name='% of Good Savings', line=dict(color='orange'), marker=dict(size=6, color='orange')))\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Volume of Applicants and % of Goods by Category - subset 2 only',\n",
        "    barmode='group',\n",
        "    xaxis_title='Category',\n",
        "    yaxis_title='Volume of Applicants',\n",
        "    template='plotly_white'  # You can change the template for the look of the plot\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n",
        "\n",
        "# Checking - keep as 4 buckets (clear difference in % goods in each bucket and logical difference between buckets)\n",
        "# Coap - 1+2 vs. 3 (logical grouping of no guarantor vs. guarantor reflected in % of goods)\n",
        "# Purpose - logical grouping: cars 1+2, small items 3,4,5, development 6,8,9, others 5,10\n",
        "# Employed - logical groupings: 1,2,3,4+5 or 1,2+3,4+5\n",
        "# Savings - logical groupings: 1,2,3,4+5 or 1,2, 3+4+5, or 1+2, 3+4+5\n"
      ],
      "metadata": {
        "id": "mSvMdUXrCYcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x2 Checking\n",
        "\n",
        "# Keeping original categories\n",
        "# IV = 0.75, but this is expected for this variable\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x2_checking = pd.crosstab(x_train2['qChecking'], x_train2['Good'], dropna=False).reset_index()\n",
        "x2_checking.columns = ['Bin', 'Bads', 'Goods']\n",
        "x2_checking = x2_checking[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x2_checking['Good%'] = x2_checking['Goods'] / x2_checking['Goods'].sum()\n",
        "x2_checking['Bad%'] = x2_checking['Bads'] / x2_checking['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x2_checking['WOE'] = np.log(x2_checking['Good%'] / x2_checking['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x2_checking['IV'] = (x2_checking['Good%'] - x2_checking['Bad%']) * x2_checking['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_chk2 = x2_checking['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x2_checking)\n",
        "print(f\"Total IV for x2_checking: {total_IV_chk2}\")"
      ],
      "metadata": {
        "id": "7tlo4junzyNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x2 Coapp\n",
        "\n",
        "# 2 bins - very low IV\n",
        "# 3 bins - very low IV\n",
        "\n",
        "# Decision - don't use: very low IV\n",
        "\n",
        "##################\n",
        "# 2 bins\n",
        "##################\n",
        "\n",
        "bins_coapp1 = [0, 2, np.inf]\n",
        "labels_coapp1 = ['No Guarantor', 'Guarantor']\n",
        "\n",
        "# Bin the 'qCoapp' values\n",
        "x_train2['qCoapp_bin'] = pd.cut(x_train2['qCoapp'], bins=bins_coapp1, labels=labels_coapp1, right=True)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x2_coap = pd.crosstab(x_train2['qCoapp_bin'], x_train2['Good'], dropna=False).reset_index()\n",
        "x2_coap.columns = ['Bin', 'Bads', 'Goods']\n",
        "x2_coap = x2_coap[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x2_coap['Good%'] = x2_coap['Goods'] / x2_coap['Goods'].sum()\n",
        "x2_coap['Bad%'] = (x2_coap['Bads'] + ep) / x2_coap['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x2_coap['WOE'] = np.log(x2_coap['Good%'] / x2_coap['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x2_coap['IV'] = (x2_coap['Good%'] - x2_coap['Bad%']) * x2_coap['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_coap = x2_coap['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x2_coap)\n",
        "print(f\"Total IV for x2_coap: {total_IV_coap}\")\n",
        "\n",
        "##################\n",
        "# 3 bins\n",
        "##################\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x2_coap = pd.crosstab(x_train2['qCoapp'], x_train2['Good'], dropna=False).reset_index()\n",
        "x2_coap.columns = ['Bin', 'Bads', 'Goods']\n",
        "x2_coap = x2_coap[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x2_coap['Good%'] = x2_coap['Goods'] / x2_coap['Goods'].sum()\n",
        "x2_coap['Bad%'] = (x2_coap['Bads'] + ep) / x2_coap['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x2_coap['WOE'] = np.log(x2_coap['Good%'] / x2_coap['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x2_coap['IV'] = (x2_coap['Good%'] - x2_coap['Bad%']) * x2_coap['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_coap = x2_coap['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x2_coap)\n",
        "print(f\"Total IV for x2_coap: {total_IV_coap}\")\n"
      ],
      "metadata": {
        "id": "0ZvGfs66zyIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X2 Purpose\n",
        "#Purpose - logical grouping: cars 0+1, small items 2,3,4, development 6,8,9, others 5,10\n",
        "\n",
        "# Decision - Very low IV - don't include\n",
        "\n",
        "purpose_mapping = {\n",
        "    0: 'Cars',\n",
        "    1: 'Cars',\n",
        "    2: 'Small Items',\n",
        "    3: 'Small Items',\n",
        "    4: 'Small Items',\n",
        "    5: 'Others',\n",
        "    6: 'Development',\n",
        "    8: 'Development',\n",
        "    9: 'Development',\n",
        "    10: 'Others'\n",
        "}\n",
        "\n",
        "# Bin the 'qPurpose' values\n",
        "x_train2['qPurp_bin'] = x_train2['qPurpose'].map(purpose_mapping)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x2_purp = pd.crosstab(x_train2['qPurp_bin'], x_train2['Good'], dropna=False).reset_index()\n",
        "x2_purp.columns = ['Bin', 'Bads', 'Goods']\n",
        "x2_purp = x2_purp[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x2_purp['Good%'] = x2_purp['Goods'] / x2_purp['Goods'].sum()\n",
        "x2_purp['Bad%'] = (x2_purp['Bads'] + ep) / x2_purp['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x2_purp['WOE'] = np.log(x2_purp['Good%'] / x2_purp['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x2_purp['IV'] = (x2_purp['Good%'] - x2_purp['Bad%']) * x2_purp['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_purp = x2_purp['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x2_purp)\n",
        "print(f\"Total IV for x2_purp: {total_IV_purp}\")"
      ],
      "metadata": {
        "id": "wFfX4kdNzx-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x2\n",
        "\n",
        "# Employed\n",
        "\n",
        "# Decision - 3 bins - IV of 0.119 only slightly lower than 4 bins\n",
        "\n",
        "##################\n",
        "# Option 1: 1, 2, 3, 4+5\n",
        "##################\n",
        "\n",
        "# Define bins and labels for Option 1\n",
        "bins_emp1 = [0, 1, 2, 3, np.inf]\n",
        "labels_emp1 = ['1', '2', '3', '4+5']\n",
        "\n",
        "# Bin the 'qEmployed' values\n",
        "x_train2['qEmployed_bin1'] = pd.cut(x_train2['qEmployed'], bins=bins_emp1, labels=labels_emp1, right=True)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x2_emp1 = pd.crosstab(x_train2['qEmployed_bin1'], x_train2['Good'], dropna=False).reset_index()\n",
        "x2_emp1.columns = ['Bin', 'Bads', 'Goods']\n",
        "x2_emp1 = x2_emp1[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x2_emp1['Good%'] = x2_emp1['Goods'] / x2_emp1['Goods'].sum()\n",
        "x2_emp1['Bad%'] = (x2_emp1['Bads'] + ep) / x2_emp1['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x2_emp1['WOE'] = np.log(x2_emp1['Good%'] / x2_emp1['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x2_emp1['IV'] = (x2_emp1['Good%'] - x2_emp1['Bad%']) * x2_emp1['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_emp1 = x2_emp1['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x2_emp1)\n",
        "print(f\"Total IV for x2_emp1: {total_IV_emp1}\")\n",
        "\n",
        "\n",
        "##################\n",
        "# Option 2: 1, 2+3, 4+5\n",
        "##################\n",
        "\n",
        "# Define bins and labels for Option 2\n",
        "bins_emp2 = [0, 1, 3, np.inf]\n",
        "labels_emp2 = ['1', '2+3', '4+5']\n",
        "\n",
        "# Bin the 'qEmployed' values\n",
        "x_train2['qEmployed_bin2'] = pd.cut(x_train2['qEmployed'], bins=bins_emp2, labels=labels_emp2, right=True)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x2_emp2 = pd.crosstab(x_train2['qEmployed_bin2'], x_train2['Good'], dropna=False).reset_index()\n",
        "x2_emp2.columns = ['Bin', 'Bads', 'Goods']\n",
        "x2_emp2 = x2_emp2[['Bin', 'Goods', 'Bads']]  # Re-order columns\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x2_emp2['Good%'] = x2_emp2['Goods'] / x2_emp2['Goods'].sum()\n",
        "x2_emp2['Bad%'] = (x2_emp2['Bads'] + ep) / x2_emp2['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x2_emp2['WOE'] = np.log(x2_emp2['Good%'] / x2_emp2['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x2_emp2['IV'] = (x2_emp2['Good%'] - x2_emp2['Bad%']) * x2_emp2['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_emp2 = x2_emp2['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x2_emp2)\n",
        "print(f\"Total IV for x2_emp2: {total_IV_emp2}\")\n"
      ],
      "metadata": {
        "id": "nJa-UjpWQg2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x2\n",
        "# Savings\n",
        "\n",
        "# Decision - include with 3 bins - slightly higher IV of 0.2\n",
        "\n",
        "##################\n",
        "# Option 1: 1, 2, 3+4+5\n",
        "##################\n",
        "\n",
        "# Define bins and labels for Option 1\n",
        "bins_sav1 = [0, 1, 2, np.inf]\n",
        "labels_sav1 = ['1', '2', '3+4+5']\n",
        "\n",
        "# Bin 'qSavings'\n",
        "x_train2.loc[:, 'qSavings_bin1'] = pd.cut(x_train2['qSavings'], bins=bins_sav1, labels=labels_sav1, right=True)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x2_sav1 = pd.crosstab(x_train2['qSavings_bin1'], x_train2['Good'], dropna=False).reset_index()\n",
        "x2_sav1.columns = ['Bin', 'Bads', 'Goods']\n",
        "x2_sav1 = x2_sav1[['Bin', 'Goods', 'Bads']]\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x2_sav1['Good%'] = x2_sav1['Goods'] / x2_sav1['Goods'].sum()\n",
        "x2_sav1['Bad%'] = (x2_sav1['Bads'] + ep) / x2_sav1['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x2_sav1['WOE'] = np.log(x2_sav1['Good%'] / x2_sav1['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x2_sav1['IV'] = (x2_sav1['Good%'] - x2_sav1['Bad%']) * x2_sav1['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_sav1 = x2_sav1['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x2_sav1)\n",
        "print(f\"Total IV for x2_sav1: {total_IV_sav1}\")\n",
        "\n",
        "\n",
        "##################\n",
        "# Option 2: 1+2, 3+4+5\n",
        "##################\n",
        "\n",
        "# Define bins and labels for Option 2\n",
        "bins_sav2 = [0, 2, np.inf]\n",
        "labels_sav2 = ['1+2', '3+4+5']\n",
        "\n",
        "# Bin 'qSavings'\n",
        "x_train2.loc[:, 'qSavings_bin2'] = pd.cut(x_train2['qSavings'], bins=bins_sav2, labels=labels_sav2, right=True)\n",
        "\n",
        "# Create a DataFrame with counts of 'Goods' and 'Bads' per bin\n",
        "x2_sav2 = pd.crosstab(x_train2['qSavings_bin2'], x_train2['Good'], dropna=False).reset_index()\n",
        "x2_sav2.columns = ['Bin', 'Bads', 'Goods']\n",
        "x2_sav2 = x2_sav2[['Bin', 'Goods', 'Bads']]\n",
        "\n",
        "# Calculate G_i/G and B_i/B\n",
        "x2_sav2['Good%'] = x2_sav2['Goods'] / x2_sav2['Goods'].sum()\n",
        "x2_sav2['Bad%'] = (x2_sav2['Bads'] + ep) / x2_sav2['Bads'].sum()\n",
        "\n",
        "# Calculate WOE for each row\n",
        "x2_sav2['WOE'] = np.log(x2_sav2['Good%'] / x2_sav2['Bad%'])\n",
        "\n",
        "# Calculate IV for each row\n",
        "x2_sav2['IV'] = (x2_sav2['Good%'] - x2_sav2['Bad%']) * x2_sav2['WOE']\n",
        "\n",
        "# Calculate total IV\n",
        "total_IV_sav2 = x2_sav2['IV'].sum()\n",
        "\n",
        "# Print results\n",
        "print(x2_sav2)\n",
        "print(f\"Total IV for x2_sav2: {total_IV_sav2}\")\n"
      ],
      "metadata": {
        "id": "aS9n0xeBSsZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### FIGURE 1 ####\n",
        "\n",
        "# Define features in order for x1\n",
        "features_x1 = ['qCoapp', 'qChecking', 'nDuration', 'qProperty', 'nInstallp', 'nAge']\n",
        "\n",
        "# Get Lasso coefficients for x1\n",
        "lasso_x1 = [\n",
        "    coef_df.loc[coef_df['feature'] == 'qCoapp_3', 'coef1'].values[0],\n",
        "    coef_df.loc[coef_df['feature'] == 'qChecking_4', 'coef1'].values[0],\n",
        "    coef_df.loc[coef_df['feature'] == 'nDuration', 'coef1'].values[0],\n",
        "    coef_df.loc[coef_df['feature'] == 'qProperty_4', 'coef1'].values[0],\n",
        "    coef_df.loc[coef_df['feature'] == 'nInstallp', 'coef1'].values[0],\n",
        "    coef_df.loc[coef_df['feature'] == 'nAge', 'coef1'].values[0]\n",
        "]\n",
        "\n",
        "# Get IVs for x1\n",
        "iv_x1 = [\n",
        "    x1_coap['IV'].sum(),\n",
        "    x1_checking['IV'].sum(),\n",
        "    x1_dur_o2['IV'].sum(),\n",
        "    x1_prop['IV'].sum(),\n",
        "    x1_installp_o3['IV'].sum(),\n",
        "    x1_age['IV'].sum()\n",
        "]\n",
        "\n",
        "# Define features in order for x2\n",
        "features_x2 = ['qChecking', 'qSavings', 'nDuration', 'qEmployed', 'nAmount', 'qCoapp', 'qPurpose', 'nInstallp']\n",
        "\n",
        "# Get Lasso coefficients for x2\n",
        "lasso_x2 = [\n",
        "    coef_df.loc[coef_df['feature'] == 'qChecking_4', 'coef2'].values[0],\n",
        "    coef_df.loc[coef_df['feature'] == 'qSavings_5', 'coef2'].values[0],\n",
        "    coef_df.loc[coef_df['feature'] == 'nDuration', 'coef2'].values[0],\n",
        "    coef_df.loc[coef_df['feature'] == 'qEmployed_4', 'coef2'].values[0],\n",
        "    coef_df.loc[coef_df['feature'] == 'nAmount', 'coef2'].values[0],\n",
        "    coef_df.loc[coef_df['feature'] == 'qCoapp_3', 'coef2'].values[0],\n",
        "    coef_df.loc[coef_df['feature'] == 'qPurpose_1', 'coef2'].values[0],\n",
        "    coef_df.loc[coef_df['feature'] == 'nInstallp', 'coef2'].values[0]\n",
        "]\n",
        "\n",
        "# Get IVs for x2\n",
        "iv_x2 = [\n",
        "    x2_checking['IV'].sum(),\n",
        "    x2_sav1['IV'].sum(),\n",
        "    x2_dur_o2['IV'].sum(),\n",
        "    x2_emp2['IV'].sum(),\n",
        "    x2_amount_o2['IV'].sum(),\n",
        "    x2_coap['IV'].sum(),\n",
        "    x2_purp['IV'].sum(),\n",
        "    x2_installp_o3['IV'].sum()\n",
        "]\n",
        "\n",
        "# Plot for x1\n",
        "fig_x1 = go.Figure()\n",
        "fig_x1.add_trace(go.Bar(x=features_x1, y=lasso_x1, name='Lasso Coefficients', marker_color='blue', text=[f\"{v:.2f}\" for v in lasso_x1], textposition='inside'))\n",
        "fig_x1.add_trace(go.Bar(x=features_x1, y=iv_x1, name='IV (Information Value)', marker_color='orange', text=[f\"{v:.2f}\" for v in iv_x1], textposition='inside'))\n",
        "fig_x1.update_layout(title='x1: Lasso Coefficients and IVs', xaxis=dict(title='Features'), yaxis=dict(title='Lasso Coefficients & IV'), barmode='group')\n",
        "\n",
        "# Plot for x2\n",
        "fig_x2 = go.Figure()\n",
        "fig_x2.add_trace(go.Bar(x=features_x2, y=lasso_x2, name='Lasso Coefficients', marker_color='blue', text=[f\"{v:.2f}\" for v in lasso_x2], textposition='inside'))\n",
        "fig_x2.add_trace(go.Bar(x=features_x2, y=iv_x2, name='IV (Information Value)', marker_color='orange', text=[f\"{v:.2f}\" for v in iv_x2], textposition='inside'))\n",
        "fig_x2.update_layout(title='x2: Lasso Coefficients and IVs', xaxis=dict(title='Features'), yaxis=dict(title='Lasso Coefficients & IV'), barmode='group')\n",
        "\n",
        "# Show the figures\n",
        "fig_x1.show()\n",
        "fig_x2.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "fpK307DpYJqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of binning decisions\n",
        "\n",
        "# Plot 2 bar charts, one for df1, one for df2. For each binning option plot a stacked bar chart of IV value."
      ],
      "metadata": {
        "id": "oyCR1pF0YJfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### FIGURE 2 ####\n",
        "\n",
        "# Define labels and IV values for x1\n",
        "features_x1_iv = ['qChecking', 'nDuration_o1', 'nDuration_o2', 'nDuration_o3', 'qProperty', 'nInstallp_o1', 'nInstallp_o2', 'nInstallp_o3']\n",
        "iv_x1_values = [\n",
        "    x1_checking['IV'].sum(),\n",
        "    x1_dur_o1['IV'].sum(),\n",
        "    x1_dur_o2['IV'].sum(),\n",
        "    x1_dur_o3['IV'].sum(),\n",
        "    x1_prop['IV'].sum(),\n",
        "    x1_installp_o1['IV'].sum(),\n",
        "    x1_installp_o2['IV'].sum(),\n",
        "    x1_installp_o3['IV'].sum()\n",
        "]\n",
        "\n",
        "# Define labels and IV values for x2\n",
        "features_x2_iv = ['qChecking', 'qSavings_o1', 'qSavings_o2', 'nDuration_o1', 'nDuration_o2', 'qEmployed_o1', 'qEmployed_o2']\n",
        "iv_x2_values = [\n",
        "    x2_checking['IV'].sum(),\n",
        "    x2_sav1['IV'].sum(),\n",
        "    x2_sav2['IV'].sum(),\n",
        "    x2_dur_o1['IV'].sum(),\n",
        "    x2_dur_o2['IV'].sum(),\n",
        "    x2_emp1['IV'].sum(),\n",
        "    x2_emp2['IV'].sum()\n",
        "]\n",
        "\n",
        "# Define colors for x1\n",
        "colors_x1 = ['green' if feature in ['qChecking', 'nDuration_o2', 'qProperty', 'nInstallp_o3'] else 'red' if feature == 'nDuration_o3' else 'grey' for feature in features_x1_iv]\n",
        "\n",
        "# Define colors for x2\n",
        "colors_x2 = ['green' if feature in ['qChecking', 'qSavings_o1', 'nDuration_o2', 'qEmployed_o2'] else 'grey' for feature in features_x2_iv]\n",
        "\n",
        "# Plot for x1\n",
        "fig_iv_x1 = go.Figure()\n",
        "fig_iv_x1.add_trace(go.Bar(x=features_x1_iv, y=iv_x1_values, name='IV (x1)', marker_color=colors_x1, text=[f\"{v:.3f}\" for v in iv_x1_values], textposition='inside'))\n",
        "\n",
        "# Add annotation for nDuration_o3 on x1\n",
        "fig_iv_x1.add_annotation(x='nDuration_o3', y=x1_dur_o3['IV'].sum(), text=\"IV too high, nDuration_o2 selected instead\", showarrow=True, arrowhead=2, ax=40, ay=-40, font=dict(color=\"red\"))\n",
        "\n",
        "fig_iv_x1.update_layout(title='Subset 1: IV scores for all considered binning options for the 4 chosen variables', xaxis=dict(title='Features'), yaxis=dict(title='IV Values'), barmode='group')\n",
        "\n",
        "# Plot for x2\n",
        "fig_iv_x2 = go.Figure()\n",
        "fig_iv_x2.add_trace(go.Bar(x=features_x2_iv, y=iv_x2_values, name='IV (x2)', marker_color=colors_x2, text=[f\"{v:.3f}\" for v in iv_x2_values], textposition='inside'))\n",
        "\n",
        "# Add annotation for qEmployed_o2 on x2\n",
        "fig_iv_x2.add_annotation(x='qEmployed_o2', y=x2_emp2['IV'].sum(), text=\"This option has 3 bins and<br>only slightly lower IV than o1 which has 4 bins\", showarrow=True, arrowhead=2, ax=40, ay=-40, font=dict(color=\"green\"))\n",
        "\n",
        "fig_iv_x2.update_layout(title='Subset 2: IV scores for all considered binning options for the 4 chosen variables', xaxis=dict(title='Features'), yaxis=dict(title='IV Values'), barmode='group')\n",
        "\n",
        "# Show the figures\n",
        "fig_iv_x1.show()\n",
        "fig_iv_x2.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "0zWksMZKdkBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create x_train1_f, x_train2_f within only the 4 selected variables in their selected bins\n",
        "\n",
        "#####\n",
        "#x1\n",
        "#####\n",
        "\n",
        "# Recreate numerical bins for safety\n",
        "x_train1_fs['nInstallp_bin'] = pd.cut(x_train1_fs['nInstallp'], bins=bins_o3, labels=labels_o3, right=True)\n",
        "x_train1_fs['nDuration_bin'] = pd.cut(x_train1_fs['nDuration'], bins=bins_x1dur2, labels=labels_x1dur2, right=True)\n",
        "\n",
        "# Create x_train1_f DataFrame\n",
        "x_train1_f = pd.DataFrame({\n",
        "    'qChecking': x_train1['qChecking'],\n",
        "    'qProp': x_train1['qProp_bin'],\n",
        "    'nInstallp': x_train1_fs['nInstallp_bin'],\n",
        "    'nDuration': x_train1_fs['nDuration_bin']\n",
        "})\n",
        "\n",
        "# Ensure x_train1_f matches the indices of y_train1\n",
        "x_train1_f = x_train1_f.loc[y_train1.index]\n",
        "\n",
        "#####\n",
        "#x2\n",
        "#####\n",
        "\n",
        "# Recreate numerical bins for safety\n",
        "x_train2_fs['nDuration_bin'] = pd.cut(x_train2_fs['nDuration'], bins=bins_dur2, labels=labels_dur2, right=True)\n",
        "\n",
        "# Create x_train2_f DataFrame\n",
        "x_train2_f = pd.DataFrame({\n",
        "    'qChecking': x_train2['qChecking'],\n",
        "    'qEmployed': x_train2['qEmployed_bin2'],\n",
        "    'qSavings': x_train2['qSavings_bin1'],\n",
        "    'nDuration': x_train2_fs['nDuration_bin']\n",
        "})\n",
        "\n",
        "# Ensure x_train2_f matches the indices of y_train2\n",
        "x_train2_f = x_train2_f.loc[y_train2.index]\n",
        "\n",
        "print(f\"x_train1_f shape: {x_train1_f.shape}\")\n",
        "print(f\"x_train2_f shape: {x_train2_f.shape}\")\n"
      ],
      "metadata": {
        "id": "Ow0wHUw2knhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create test sets with appropriately binned chosen variables\n",
        "\n",
        "#####\n",
        "# x1 - Test\n",
        "#####\n",
        "\n",
        "# Unscale x_test1 using scaler1\n",
        "x_test1_fs = pd.DataFrame(scaler1.inverse_transform(x_test1[numerical_cols]), columns=x_test1[numerical_cols].columns, index=x_test1.index)\n",
        "\n",
        "# Create numerical bins\n",
        "x_test1_fs['nInstallp_bin'] = pd.cut(x_test1_fs['nInstallp'], bins=bins_o3, labels=labels_o3, right=True)\n",
        "x_test1_fs['nDuration_bin'] = pd.cut(x_test1_fs['nDuration'], bins=bins_x1dur2, labels=labels_x1dur2, right=True)\n",
        "\n",
        "# Create qProperty bins\n",
        "x_test1['qProp_bin'] = pd.cut(x_test1['qProperty'], bins=bins_prop1, labels=labels_prop1, right=True)\n",
        "\n",
        "# Create x_test1_f DataFrame\n",
        "x_test1_f = pd.DataFrame({\n",
        "    'qChecking': x_test1['qChecking'],\n",
        "    'qProp': x_test1['qProp_bin'],\n",
        "    'nInstallp': x_test1_fs['nInstallp_bin'],\n",
        "    'nDuration': x_test1_fs['nDuration_bin']\n",
        "})\n",
        "\n",
        "# Ensure x_test1_f matches the indices of y_test1\n",
        "x_test1_f = x_test1_f.loc[y_test1.index]\n",
        "\n",
        "#####\n",
        "# x2 - Test\n",
        "#####\n",
        "\n",
        "# Unscale x_test2 using scaler2\n",
        "x_test2_fs = pd.DataFrame(scaler2.inverse_transform(x_test2[numerical_cols]), columns=x_test2[numerical_cols].columns, index=x_test2.index)\n",
        "\n",
        "# Create numerical bins\n",
        "x_test2_fs['nDuration_bin'] = pd.cut(x_test2_fs['nDuration'], bins=bins_dur2, labels=labels_dur2, right=True)\n",
        "\n",
        "# Create qEmployed_bin2 and qSavings_bin1\n",
        "x_test2['qEmployed_bin2'] = pd.cut(x_test2['qEmployed'], bins=bins_emp2, labels=labels_emp2, right=True)\n",
        "x_test2['qSavings_bin1'] = pd.cut(x_test2['qSavings'], bins=bins_sav1, labels=labels_sav1, right=True)\n",
        "\n",
        "# Create x_test2_f DataFrame\n",
        "x_test2_f = pd.DataFrame({\n",
        "    'qChecking': x_test2['qChecking'],\n",
        "    'qEmployed': x_test2['qEmployed_bin2'],\n",
        "    'qSavings': x_test2['qSavings_bin1'],\n",
        "    'nDuration': x_test2_fs['nDuration_bin']\n",
        "})\n",
        "\n",
        "# Ensure x_test2_f matches the indices of y_test2\n",
        "x_test2_f = x_test2_f.loc[y_test2.index]\n",
        "\n",
        "# Print shapes for confirmation\n",
        "print(f\"x_test1_f shape: {x_test1_f.shape}\") # should be 72\n",
        "print(f\"x_test2_f shape: {x_test2_f.shape}\") # should be 129\n"
      ],
      "metadata": {
        "id": "q5QUe6gDsLdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encode x_train1_f, x_train2_f\n",
        "\n",
        "x_train1_enc_f = pd.get_dummies(x_train1_f, columns=['qChecking','qProp','nInstallp','nDuration'], drop_first=True, dtype=int)\n",
        "x_train2_enc_f = pd.get_dummies(x_train2_f, columns=['qChecking','qEmployed','qSavings','nDuration'], drop_first=True, dtype=int)\n",
        "\n",
        "x_test1_enc_f = pd.get_dummies(x_test1_f, columns=['qChecking','qProp','nInstallp','nDuration'], drop_first=True, dtype=int)\n",
        "x_test2_enc_f = pd.get_dummies(x_test2_f, columns=['qChecking','qEmployed','qSavings','nDuration'], drop_first=True, dtype=int)\n",
        "\n",
        "# Create list of names of encoded categorical columns\n",
        "categorical_cols_enc1 = [col for col in x_train1_enc_f.columns]\n",
        "print(f\"Categorical columns x_train1: {categorical_cols_enc1}\")\n",
        "categorical_cols_enc1_ts = [col for col in x_test1_enc_f.columns]\n",
        "print(f\"Categorical columns x_test1: {categorical_cols_enc1_ts}\")\n",
        "categorical_cols_enc2 = [col for col in x_train2_enc_f.columns]\n",
        "print(f\"Categorical columns x_train2: {categorical_cols_enc2}\")\n",
        "categorical_cols_enc2_ts = [col for col in x_test2_enc_f.columns]\n",
        "print(f\"Categorical columns x_test2: {categorical_cols_enc2_ts}\")"
      ],
      "metadata": {
        "id": "Y8W3ohbhqHYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 4"
      ],
      "metadata": {
        "id": "MUo1JDzAkCIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a constant for statsmodels\n",
        "xtn_1 = sm.add_constant(x_train1_enc_f)\n",
        "xtn_2 = sm.add_constant(x_train2_enc_f)\n",
        "\n",
        "# Define factor and offset - same for all models\n",
        "factor = round(20 / np.log(2), 2)\n",
        "offset = round(600 - factor * np.log(50), 2)\n",
        "\n",
        "factor, offset"
      ],
      "metadata": {
        "id": "qzzwPKECH-Ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fit all models"
      ],
      "metadata": {
        "id": "BaSDBpHOcdHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset 1 (<=12 months) - Linear Regression\n",
        "\n",
        "lin_model1 = sm.OLS(y_train1, xtn_1)\n",
        "lin_res1 = lin_model1.fit()\n",
        "print(lin_res1.summary())\n",
        "y_tn1_lin_pp = lin_res1.predict(xtn_1)\n",
        "y_tn1_lin_pp = np.clip(y_tn1_lin_pp, 0, 1-ep) # clipping to prevent negative or infinite probabilty predictions which would result in NaN score"
      ],
      "metadata": {
        "id": "CbNbE7pDkTWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset 1 (<=12 months) - Logistic Regression\n",
        "\n",
        "log_model1 = sm.Logit(y_train1, xtn_1)\n",
        "log_res1 = log_model1.fit()\n",
        "print(log_res1.summary())\n",
        "y_tn1_log_pp = log_res1.predict(xtn_1)"
      ],
      "metadata": {
        "id": "3eh35Oo7kTUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset 2 (>12 months) - Linear Regression\n",
        "\n",
        "lin_model2 = sm.OLS(y_train2, xtn_2)\n",
        "lin_res2 = lin_model2.fit()\n",
        "print(lin_res2.summary())\n",
        "y_tn2_lin_pp = lin_res2.predict(xtn_2)\n",
        "y_tn2_lin_pp = np.clip(y_tn2_lin_pp, 0, 1-ep) # clipping to prevent negative or infinite probabilty predictions which would result in NaN score"
      ],
      "metadata": {
        "id": "2C0ZTi53kTMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset 2 (>12 months) - Logistic Regression\n",
        "\n",
        "log_model2 = sm.Logit(y_train2, xtn_2)\n",
        "log_res2 = log_model2.fit()\n",
        "print(log_res2.summary())\n",
        "y_tn2_log_pp = log_res2.predict(xtn_2)"
      ],
      "metadata": {
        "id": "QEzZeSJrveRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculate scores"
      ],
      "metadata": {
        "id": "K2cr2JxHcrG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset 1 (<=12 months) - Linear Regression\n",
        "\n",
        "# calculate score\n",
        "xtn_1['P1_lin1'] = y_tn1_lin_pp\n",
        "xtn_1['P0_lin1'] = 1-y_tn1_lin_pp # this is the complement of P_1\n",
        "xtn_1['Score_lin'] = np.ceil(np.log(xtn_1['P1_lin1']/xtn_1['P0_lin1']) * factor + offset)\n",
        "xtn_1\n",
        "xtn_1['Score_lin'].describe()"
      ],
      "metadata": {
        "id": "JXwdsRWdbWgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset 1 (<=12 months) - Logistic Regression\n",
        "\n",
        "# calculate score\n",
        "xtn_1['P1_log1'] = y_tn1_log_pp\n",
        "xtn_1['P0_log1'] = 1-y_tn1_log_pp # this is the complement of P_1\n",
        "xtn_1['Score_log'] = np.ceil(np.log(xtn_1['P1_log1']/xtn_1['P0_log1']) * factor + offset)\n",
        "xtn_1\n",
        "xtn_1['Score_log'].describe()"
      ],
      "metadata": {
        "id": "twVURobGKV4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtn_1"
      ],
      "metadata": {
        "id": "iNo4xTjwVuQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset 2 (>12 months) - Linear Regression\n",
        "\n",
        "# calculate score\n",
        "xtn_2['P1_lin2'] = y_tn2_lin_pp\n",
        "xtn_2['P0_lin2'] = 1-y_tn2_lin_pp # this is the complement of P_1\n",
        "xtn_2['Score_lin'] = np.ceil(np.log(xtn_2['P1_lin2']/xtn_2['P0_lin2']) * factor + offset)\n",
        "xtn_2\n",
        "xtn_2['Score_lin'].describe()"
      ],
      "metadata": {
        "id": "PWO2x6Bkbw_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset 2 (>12 months) - Logistic Regression\n",
        "\n",
        "# calculate score\n",
        "xtn_2['P1_log2'] = y_tn2_log_pp\n",
        "xtn_2['P0_log2'] = 1-y_tn2_log_pp # this is the complement of P_1\n",
        "xtn_2['Score_log'] = np.ceil(np.log(xtn_2['P1_log2']/xtn_2['P0_log2']) * factor + offset)\n",
        "xtn_2\n",
        "xtn_2['Score_log'].describe()"
      ],
      "metadata": {
        "id": "n2gUSS8aW-sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtn_2"
      ],
      "metadata": {
        "id": "dnxdAUkBhDxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Coefficient tables for appendix*"
      ],
      "metadata": {
        "id": "oHxXOdqAYBWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lin1\n",
        "\n",
        "# Extract regression coefficients into a df\n",
        "param_lin1 = lin_res1.params\n",
        "coef_lin1 = pd.DataFrame({'Var': param_lin1.index, 'Coef': param_lin1.values})\n",
        "coef_lin1"
      ],
      "metadata": {
        "id": "7Zj9Cgb8YBAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# log1\n",
        "\n",
        "# Extract regression coefficients into a df\n",
        "param_log1 = log_res1.params\n",
        "coef_log1 = pd.DataFrame({'Var': param_log1.index, 'Coef': param_log1.values})\n",
        "\n",
        "# Add missing bins for each variable\n",
        "add_rows1 = pd.DataFrame({\n",
        "    'Var': [\n",
        "        'checking_ref',\n",
        "        'property_ref',\n",
        "        'installp_ref',\n",
        "        'duration_ref'\n",
        "    ],\n",
        "    'Coef': [0,0,0,0]\n",
        "})\n",
        "\n",
        "# Specify insert position\n",
        "insert_after = {\n",
        "    'qChecking_4': 'checking_ref',\n",
        "    'qProp_Unk_Na': 'property_ref',\n",
        "    'nInstallp_4+ Installp': 'installp_ref',\n",
        "    'nDuration_12': 'duration_ref'\n",
        "}\n",
        "\n",
        "# Results df\n",
        "coef_log11 = coef_log1.copy()\n",
        "\n",
        "# Insert\n",
        "for position, new_row in insert_after.items():\n",
        "  idx = coef_log11.index[coef_log11['Var'] == position][0]+1\n",
        "  top = coef_log11.iloc[:idx, :]\n",
        "  bottom = coef_log11.iloc[idx:,:]\n",
        "  new_row = pd.DataFrame([[new_row, 0]], columns=coef_log11.columns)\n",
        "  coef_log11 = pd.concat([top, new_row, bottom], ignore_index=True)\n",
        "\n",
        "coef_log11"
      ],
      "metadata": {
        "id": "bltbTvWBYA81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lin2\n",
        "\n",
        "# Extract regression coefficients into a df\n",
        "param_lin2 = lin_res2.params\n",
        "coef_lin2 = pd.DataFrame({'Var': param_lin2.index, 'Coef': param_lin2.values})\n",
        "coef_lin2"
      ],
      "metadata": {
        "id": "u0383pM4YA6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# log2\n",
        "\n",
        "# Extract regression coefficients into a df\n",
        "param_log2 = log_res2.params\n",
        "coef_log2 = pd.DataFrame({'Var': param_log2.index, 'Coef': param_log2.values})\n",
        "\n",
        "# Add missing bins for each variable\n",
        "add_rows2 = pd.DataFrame({\n",
        "    'Var': [\n",
        "        'checking_ref',\n",
        "        'employed_ref',\n",
        "        'savings_ref',\n",
        "        'duration_ref'\n",
        "    ],\n",
        "    'Coef': [0, 0, 0, 0]\n",
        "})\n",
        "\n",
        "# Specify insert position\n",
        "insert_after = {\n",
        "    'qChecking_4': 'checking_ref',\n",
        "    'qEmployed_4+5': 'employed_ref',\n",
        "    'qSavings_3+4+5': 'savings_ref',\n",
        "    'nDuration_48+': 'duration_ref'\n",
        "}\n",
        "\n",
        "# Results df\n",
        "coef_log22 = coef_log2.copy()\n",
        "\n",
        "# Insert\n",
        "for position, new_row in insert_after.items():\n",
        "    idx = coef_log22.index[coef_log22['Var'] == position][0] + 1\n",
        "    top = coef_log22.iloc[:idx, :]\n",
        "    bottom = coef_log22.iloc[idx:, :]\n",
        "    new_row_df = pd.DataFrame([[new_row, 0]], columns=coef_log22.columns)\n",
        "    coef_log22 = pd.concat([top, new_row_df, bottom], ignore_index=True)\n",
        "\n",
        "coef_log22"
      ],
      "metadata": {
        "id": "BgFNd462YA38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 5\n",
        "\n",
        "Validation set:\n",
        "* RoC curves\n",
        "* Sensitivity and Specifity calculations\n",
        "* Gini coefficient\n",
        "* KS values"
      ],
      "metadata": {
        "id": "OAdodOLCKeOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the test set\n",
        "# Add constant\n",
        "xtt_1 = sm.add_constant(x_test1_enc_f)\n",
        "xtt_2 = sm.add_constant(x_test2_enc_f)\n",
        "\n",
        "# Predictions\n",
        "y_tt1_lin_pp = lin_res1.predict(xtt_1)\n",
        "y_tt1_lin_pp = np.clip(y_tt1_lin_pp, 0, 1-ep)# clip\n",
        "y_tt1_log_pp = log_res1.predict(xtt_1)\n",
        "y_tt2_lin_pp = lin_res2.predict(xtt_2)\n",
        "y_tt2_lin_pp = np.clip(y_tt2_lin_pp, 0, 1-ep)# clip\n",
        "y_tt2_log_pp = log_res2.predict(xtt_2)\n"
      ],
      "metadata": {
        "id": "kmBPIfrHiw9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC curves\n",
        "\n",
        "# Define models and test sets\n",
        "models_test1 = {\n",
        "    'y_tt1_lin_pp': y_tt1_lin_pp,\n",
        "    'y_tt1_log_pp': y_tt1_log_pp\n",
        "}\n",
        "\n",
        "models_test2 = {\n",
        "    'y_tt2_lin_pp': y_tt2_lin_pp,\n",
        "    'y_tt2_log_pp': y_tt2_log_pp\n",
        "}\n",
        "\n",
        "# Plot ROC curves for y_test1\n",
        "plt.figure(figsize=(8, 6))\n",
        "for model_name, y_pred in models_test1.items():\n",
        "    # Compute ROC curve and AUC\n",
        "    fpr, tpr, thresholds = roc_curve(y_test1, y_pred)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # Plot\n",
        "    plt.plot(fpr, tpr, lw=2, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "# Plot diagonal reference line\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves for subset 1 (Duration <=12 months)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Plot ROC curves for y_test2\n",
        "plt.figure(figsize=(8, 6))\n",
        "for model_name, y_pred in models_test2.items():\n",
        "    # Compute ROC curve and AUC\n",
        "    fpr, tpr, thresholds = roc_curve(y_test2, y_pred)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # Plot\n",
        "    plt.plot(fpr, tpr, lw=2, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "# Plot diagonal reference line\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves for subset 2 (Duration >12 months)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EGuNFGbskMpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specificity and Sensitivity\n",
        "\n",
        "# Specificity = TN/(TN/FP) = True Negative Rate\n",
        "# Sensitivity = TP/(TP/FN) = True Positive Rate = Recall\n",
        "\n",
        "# Define model predictions and test sets\n",
        "predictions = {\n",
        "    'y_tt1_lin_pp': y_tt1_lin_pp,\n",
        "    'y_tt1_log_pp': y_tt1_log_pp,\n",
        "    'y_tt2_lin_pp': y_tt2_lin_pp,\n",
        "    'y_tt2_log_pp': y_tt2_log_pp\n",
        "}\n",
        "\n",
        "test_sets = {\n",
        "    'y_tt1_lin_pp': y_test1,\n",
        "    'y_tt1_log_pp': y_test1,\n",
        "    'y_tt2_lin_pp': y_test2,\n",
        "    'y_tt2_log_pp': y_test2\n",
        "}\n",
        "\n",
        "# Loop through predictions\n",
        "for name, y_pred in predictions.items():\n",
        "    # Generate class predictions with 0.5 threshold\n",
        "    y_class = (y_pred > 0.5).astype(int)\n",
        "\n",
        "    # Get the corresponding test set\n",
        "    y_test = test_sets[name]\n",
        "\n",
        "    # Generate the confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_class)\n",
        "    tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "    # Calculate Specificity and Sensitivity\n",
        "    specificity = tn / (tn + fp)\n",
        "    sensitivity = tp / (tp + fn)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Bad', 'Good'], yticklabels=['Bad', 'Good'])\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix for {name}')\n",
        "    plt.show()\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Specificity (True Negative Rate) for {name}: {specificity:.2f}\")\n",
        "    print(f\"Sensitivity (True Positive Rate/Recall) for {name}: {sensitivity:.2f}\\n\")"
      ],
      "metadata": {
        "id": "rM6MOdl7oL_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gini coefficient\n",
        "\n",
        "# G = 2AUROC-1\n",
        "\n",
        "# Calculate AUROC for each model\n",
        "# Subset 1 - linear\n",
        "fpr_lin1, tpr_lin1, thresholds_lin1 = roc_curve(y_test1, y_tt1_lin_pp)\n",
        "roc_auc_lin1 = auc(fpr_lin1, tpr_lin1)\n",
        "# Subset 1 - logistic\n",
        "fpr_log1, tpr_log1, thresholds_log1 = roc_curve(y_test1, y_tt1_log_pp)\n",
        "roc_auc_log1 = auc(fpr_log1, tpr_log1)\n",
        "\n",
        "# Subset 2 - linear\n",
        "fpr_lin2, tpr_lin2, thresholds_lin2 = roc_curve(y_test2, y_tt2_lin_pp)\n",
        "roc_auc_lin2 = auc(fpr_lin2, tpr_lin2)\n",
        "# Subset 2 - logistic\n",
        "fpr_log2, tpr_log2, thresholds_log2 = roc_curve(y_test2, y_tt2_log_pp)\n",
        "roc_auc_log2 = auc(fpr_log2, tpr_log2)\n",
        "\n",
        "# Calculate Gini Coefficients for each model\n",
        "gini_lin1 = 2 * roc_auc_lin1 - 1\n",
        "gini_log1 = 2 * roc_auc_log1 - 1\n",
        "\n",
        "gini_lin2 = 2 * roc_auc_lin2 - 1\n",
        "gini_log2 = 2 * roc_auc_log2 - 1\n",
        "\n",
        "\n",
        "# Print Gini Coefficients for each model\n",
        "print(f\"Gini coefficient for subset 1 linear regression: {gini_lin1:.2f}\")\n",
        "print(f\"Gini coefficient for subset 1 logistic regression: {gini_log1:.2f}\\n\")\n",
        "print(f\"Gini coefficient for subset 2 linear regression: {gini_lin2:.2f}\")\n",
        "print(f\"Gini coefficient for subset 2 logistic regression: {gini_log2:.2f}\\n\")"
      ],
      "metadata": {
        "id": "6nH2HJbKqh5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kolmogorov-Smirnov Value\n",
        "\n",
        "# maximum absolute difference in F(s|B) and F(s|G)\n",
        "\n",
        "# Calculate scores for each sample in the test set\n",
        "\n",
        "# Subset 1 (<=12 months) - LinearRegression\n",
        "# calculate score\n",
        "xtt_1['P1_lin1'] = y_tt1_lin_pp\n",
        "xtt_1['P0_lin1'] = 1-y_tt1_lin_pp\n",
        "xtt_1['Score_lin'] = np.ceil(np.log(xtt_1['P1_lin1']/xtt_1['P0_lin1']) * factor + offset)\n",
        "xtt_1\n",
        "#print(xtt_1['Score_lin'].describe())\n",
        "\n",
        "# Subset 1 (<=12 months) - Logistic Regression\n",
        "# calculate score\n",
        "xtt_1['P1_log1'] = y_tt1_log_pp\n",
        "xtt_1['P0_log1'] = 1-y_tt1_log_pp\n",
        "xtt_1['Score_log'] = np.ceil(np.log(xtt_1['P1_log1']/xtt_1['P0_log1']) * factor + offset)\n",
        "xtt_1\n",
        "#print(xtt_1['Score_log'].describe())\n",
        "\n",
        "\n",
        "# Subset 2 (>12 months) - LinearRegression\n",
        "# calculate score\n",
        "xtt_2['P1_lin2'] = y_tt2_lin_pp\n",
        "xtt_2['P0_lin2'] = 1-y_tt2_lin_pp\n",
        "xtt_2['Score_lin'] = np.ceil(np.log(xtt_2['P1_lin2']/xtt_2['P0_lin2']) * factor + offset)\n",
        "xtt_2\n",
        "#print(xtt_2['Score_lin'].describe())\n",
        "\n",
        "# Subset 2 (>12 months) - Logistic Regression\n",
        "# calculate score\n",
        "xtt_2['P1_log2'] = y_tt2_log_pp\n",
        "xtt_2['P0_log2'] = 1-y_tt2_log_pp\n",
        "xtt_2['Score_log'] = np.ceil(np.log(xtt_2['P1_log2']/xtt_2['P0_log2']) * factor + offset)\n",
        "xtt_2\n",
        "#print(xtt_2['Score_log'].describe())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "l-myS_TkDE7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df for Kolmogorov-Smirnov Value for Subset 1 (<=12 months) - LinearRegression\n",
        "ks_lin1 = pd.DataFrame({\n",
        "    'Score': xtt_1['Score_lin'],\n",
        "    'Actual': y_test1\n",
        "}).sort_values(by='Score', ascending=True)\n",
        "\n",
        "# cumulative FN\n",
        "ks_lin1['FN'] = ks_lin1['Actual'].cumsum()\n",
        "\n",
        "# cumulative TN\n",
        "ks_lin1['TN'] = ks_lin1['Actual'].eq(0).cumsum()\n",
        "\n",
        "# Add cumulative FP\n",
        "ks_lin1['FP'] = ks_lin1['TN'].iloc[-1] - ks_lin1['TN']\n",
        "\n",
        "# Add cumulative TP\n",
        "ks_lin1['TP'] = ks_lin1['FN'].iloc[-1] - ks_lin1['FN']\n",
        "\n",
        "# F(s|G)\n",
        "ks_lin1['F(s|G)'] = ks_lin1['FN'] / ks_lin1['FN'].iloc[-1]\n",
        "\n",
        "# F(s|B)\n",
        "ks_lin1['F(s|B)'] = ks_lin1['TN'] / ks_lin1['TN'].iloc[-1]\n",
        "\n",
        "# Kolmogorov-Smirnov Value\n",
        "ks_lin1['KS_Stat'] = abs(ks_lin1['F(s|G)'] - ks_lin1['F(s|B)'])\n",
        "\n",
        "print(ks_lin1['KS_Stat'].max())\n",
        "# ks_lin1"
      ],
      "metadata": {
        "id": "kpo-zYRyHLPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df for Kolmogorov-Smirnov Value for Subset 1 (<=12 months) - LogisticRegression\n",
        "ks_log1 = pd.DataFrame({\n",
        "    'Score': xtt_1['Score_log'],\n",
        "    'Actual': y_test1\n",
        "}).sort_values(by='Score', ascending=True)\n",
        "\n",
        "# cumulative FN\n",
        "ks_log1['FN'] = ks_log1['Actual'].cumsum()\n",
        "\n",
        "# cumulative TN\n",
        "ks_log1['TN'] = ks_log1['Actual'].eq(0).cumsum()\n",
        "\n",
        "# Add cumulative FP\n",
        "ks_log1['FP'] = ks_log1['TN'].iloc[-1] - ks_log1['TN']\n",
        "\n",
        "# Add cumulative TP\n",
        "ks_log1['TP'] = ks_log1['FN'].iloc[-1] - ks_log1['FN']\n",
        "\n",
        "# F(s|G)\n",
        "ks_log1['F(s|G)'] = ks_log1['FN'] / ks_log1['FN'].iloc[-1]\n",
        "\n",
        "# F(s|B)\n",
        "ks_log1['F(s|B)'] = ks_log1['TN'] / ks_log1['TN'].iloc[-1]\n",
        "\n",
        "# Kolmogorov-Smirnov Value\n",
        "ks_log1['KS_Stat'] = abs(ks_log1['F(s|G)'] - ks_log1['F(s|B)'])\n",
        "\n",
        "print(ks_log1['KS_Stat'].max())\n",
        "# ks_log1"
      ],
      "metadata": {
        "id": "i95Udwc2HLMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df for Kolmogorov-Smirnov Value for Subset 2 (>12 months) - LinearRegression\n",
        "ks_lin2 = pd.DataFrame({\n",
        "    'Score': xtt_2['Score_lin'],\n",
        "    'Actual': y_test2\n",
        "}).sort_values(by='Score', ascending=True)\n",
        "\n",
        "# cumulative FN\n",
        "ks_lin2['FN'] = ks_lin2['Actual'].cumsum()\n",
        "\n",
        "# cumulative TN\n",
        "ks_lin2['TN'] = ks_lin2['Actual'].eq(0).cumsum()\n",
        "\n",
        "# Add cumulative FP\n",
        "ks_lin2['FP'] = ks_lin2['TN'].iloc[-1] - ks_lin2['TN']\n",
        "\n",
        "# Add cumulative TP\n",
        "ks_lin2['TP'] = ks_lin2['FN'].iloc[-1] - ks_lin2['FN']\n",
        "\n",
        "# F(s|G)\n",
        "ks_lin2['F(s|G)'] = ks_lin2['FN'] / ks_lin2['FN'].iloc[-1]\n",
        "\n",
        "# F(s|B)\n",
        "ks_lin2['F(s|B)'] = ks_lin2['TN'] / ks_lin2['TN'].iloc[-1]\n",
        "\n",
        "# Kolmogorov-Smirnov Value\n",
        "ks_lin2['KS_Stat'] = abs(ks_lin2['F(s|G)'] - ks_lin2['F(s|B)'])\n",
        "\n",
        "print(ks_lin2['KS_Stat'].max())\n",
        "# ks_lin2"
      ],
      "metadata": {
        "id": "Q_dbRSBdHLKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame for Score_log - xtt_2\n",
        "ks_log2 = pd.DataFrame({\n",
        "    'Score': xtt_2['Score_log'],\n",
        "    'Actual': y_test2\n",
        "}).sort_values(by='Score', ascending=True)\n",
        "\n",
        "# cumulative FN\n",
        "ks_log2['FN'] = ks_log2['Actual'].cumsum()\n",
        "\n",
        "# cumulative TN\n",
        "ks_log2['TN'] = ks_log2['Actual'].eq(0).cumsum()\n",
        "\n",
        "# Add cumulative FP\n",
        "ks_log2['FP'] = ks_log2['TN'].iloc[-1] - ks_log2['TN']\n",
        "\n",
        "# Add cumulative TP\n",
        "ks_log2['TP'] = ks_log2['FN'].iloc[-1] - ks_log2['FN']\n",
        "\n",
        "# F(s|G)\n",
        "ks_log2['F(s|G)'] = ks_log2['FN'] / ks_log2['FN'].iloc[-1]\n",
        "\n",
        "# F(s|B)\n",
        "ks_log2['F(s|B)'] = ks_log2['TN'] / ks_log2['TN'].iloc[-1]\n",
        "\n",
        "# Kolmogorov-Smirnov Value\n",
        "ks_log2['KS_Stat'] = abs(ks_log2['F(s|G)'] - ks_log2['F(s|B)'])\n",
        "\n",
        "print(ks_log2['KS_Stat'].max())\n",
        "# ks_log2"
      ],
      "metadata": {
        "id": "3kMaalo5HLH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print KS results for each model\n",
        "\n",
        "print(f\"Kolmogrov-Smirnov statistic for subset 1 linear regression: {ks_lin1['KS_Stat'].max():.3f}\")\n",
        "print(f\"Kolmogrov-Smirnov statistic for subset 1 logistic regression: {ks_log1['KS_Stat'].max():.3f}\\n\")\n",
        "print(f\"Kolmogrov-Smirnov statistic for subset 2 linear regression: {ks_lin2['KS_Stat'].max():.3f}\")\n",
        "print(f\"Kolmogrov-Smirnov statistic for subset 2 logistic regression: {ks_log2['KS_Stat'].max():.3f}\\n\")"
      ],
      "metadata": {
        "id": "TM4CIAveSJu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot KS curves for each model\n",
        "\n",
        "# List of ks_ dataframes and their corresponding titles\n",
        "ks_dfs = [ks_lin1, ks_log1, ks_lin2, ks_log2,]\n",
        "titles = ['KS - <=12 months - Linear', 'KS <=12 months - Logistic', 'KS >12 months - Linear', 'KS >12 months - Logistic']\n",
        "\n",
        "# Create a 2x2 subplot\n",
        "fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Loop over the ks_dfs and plot\n",
        "for i, (ks_df, title) in enumerate(zip(ks_dfs, titles)):\n",
        "    row = i // 2\n",
        "    col = i % 2\n",
        "\n",
        "    # Plot the F(s|G) and F(s|B) curves against score\n",
        "    axs[row, col].plot(ks_df['Score'], ks_df['F(s|G)'], label='F(s|G)', color='blue')\n",
        "    axs[row, col].plot(ks_df['Score'], ks_df['F(s|B)'], label='F(s|B)', color='orange')\n",
        "\n",
        "    # Set labels and title\n",
        "    axs[row, col].set_xlabel('Score')\n",
        "    axs[row, col].set_ylabel('Cumulative Probability')\n",
        "    axs[row, col].set_title(f'{title} - KS = {ks_df[\"KS_Stat\"].max():.3f}')\n",
        "    axs[row, col].legend()\n",
        "\n",
        "# Adjust layout for better spacing\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-SYVul11Q61s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p_lHaykiYidw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}